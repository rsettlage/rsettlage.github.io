[
  {
    "path": "mcmc/2022-06-14-box-muller-tldr/",
    "title": "Box-Muller-tldr",
    "description": "A short introction to Box-Muller to generate two independent random normals.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-17",
    "categories": [
      "MCMC",
      "Box-Muller"
    ],
    "contents": "\n\nContents\nGoal: generate\n2 independent N(0,1) variables\nProof\nExample 1\nExample 2\n\nGoal: generate 2\nindependent N(0,1) variables\nStep 1 : generate data from 2 independent random uniform\nvariables\n\\[\n\\begin{eqnarray}\nu_1 \\sim unif(0,1) \\\\\nu_2 \\sim unif(0,1)\n\\end{eqnarray}\n\\]\nStep 2:\ndefine:\n\\[\n\\begin{eqnarray} \\\\\n\\tag{1}\n\\Theta &=& 2\\pi u_2 \\\\\n\\tag{2}\nR &=& \\sqrt{-2log(u_1)}\n\\end{eqnarray}\n\\]\ncompute:\n\\[\n\\begin{equation}\n\\tag{3}\ng(u_1,u_2) = \\begin{cases}\nx_1 &=& R cos \\Theta \\\\\nx_2 &=& R sin \\Theta\n\\end{cases}\n\\end{equation}\n\\]\nclaim:\n\\[\n\\begin{eqnarray}\nX_1 \\perp \\!\\!\\! \\perp X_2\n\\end{eqnarray}\n\\]\nProof\nWe just need to transform and find pdf of \\(X_1\\) and \\(X_2\\).\n\\[\n\\begin{eqnarray}\n\\tag{4}\nP_{X_1,X_2}(x_1,x_2) &=& P_{u_1,u_2}g^{-1}(u1,u2)\\cdot \\mid J\n\\mid \\\\\n\\tag{5}\nJ &=& \\begin{vmatrix}\n   \\tfrac{\\partial u_1}{\\partial x_1} & \\tfrac{\\partial\nu_1}{\\partial x_2}  \\\\\n   \\tfrac{\\partial u_2}{\\partial x_1} & \\tfrac{\\partial\nu_2}{\\partial x_2}  \\\\\n   \\end{vmatrix}\n\\end{eqnarray}\n\\]\nnoting that \\(P_{u_1,u_2}g^{-1}(u1,u2) =\nP_{u_1}(u_1) P_{u_2}(u_2) = 1\\cdot 1 = 1\\).\nNow,\n\\[\n\\begin{eqnarray}\nx_1^2 + x_2^2 &=& R^2 \\\\\n  &=& -2\\cdot log (u_1) \\\\\n  \\tag{6}\n  \\Rightarrow u_1 &=& e^{-\\tfrac{1}{2}(x_1^2+x_2^2)}\n\\end{eqnarray}\n\\]\nAnd\n\\[\n\\begin{eqnarray}\n\\frac{x_1}{x_2} &=& \\frac{cos \\Theta}{sin \\Theta} \\\\\n  &=& tan \\Theta \\\\\n  &=& tan (2 \\pi u_2) \\\\\n  \\tag{7}\n  \\Rightarrow u_2 &=&\\frac{1}{2\\pi}tan^{-1}(\\frac{x_2}{x_1})\n\\end{eqnarray}\n\\] Taken together: \\[\n\\begin{equation}\n\\tag{8}\ng^{-1}(u_1,u_2) = \\begin{cases}\nu_1 &=& e^{-\\tfrac{1}{2}(x_1^2+x_2^2)} \\\\\nu_2 &=&\\frac{1}{2\\pi}tan^{-1}(\\frac{x_2}{x_1})\n\\end{cases}\n\\end{equation}\n\\]\nNow to compute the Jacobian using the definitions of \\(u_1\\) and \\(u_2\\) just given:\n\\[\n\\begin{eqnarray}\nP_{X_1,X_2}(x_1,x_2) &=& P_{u_1,u_2}g^{-1}(u1,u2)\\cdot \\mid J\n\\mid \\\\\nJ &=& \\begin{vmatrix}\n   \\tfrac{\\partial u_1}{\\partial x_1} & \\tfrac{\\partial\nu_1}{\\partial x_2}  \\\\\n   \\tfrac{\\partial u_2}{\\partial x_1} & \\tfrac{\\partial\nu_2}{\\partial x_2}  \\\\\n   \\end{vmatrix} \\\\\n   &=& \\begin{vmatrix}\n   -x_1 e^{-\\tfrac{1}{2}(x_1^2+x_2^2)} &\n-\\frac{1}{2\\pi}\\frac{x_2^2}{x_1^2+x_2^2}  \\\\\n   -x_2 e^{-\\tfrac{1}{2}(x_1^2+x_2^2)} &\n-\\frac{1}{2\\pi}\\frac{x_1^2}{x_1^2+x_2^2}  \\\\\n   \\end{vmatrix} \\\\\n   &=& \\frac{1}{2\\pi}e^{-\\tfrac{1}{2}(x_1^2+x_2^2)} \\\\\n   \\tag{9}\n   &=&{\\underbrace\n{\\frac{1}{\\sqrt{2\\pi}}e^{-\\tfrac{1}{2}x_1^2}}_{ {N(0,1)}}} \\cdot\n{\\underbrace {\\frac{1}{\\sqrt{2\\pi}}e^{-\\tfrac{1}{2}x_2^2}}_{ {N(0,1)}}}\n\\end{eqnarray}\n\\] Finally, we can now use Box-Muller.\nExample 1\nLet’s do it:\n\n\n# draw u1 and u2 as unifs\n  draws <- 10000\n# draw u1,u2\n  set.seed(194756)\n  u1 <- runif(draws)\n  set.seed(194396)\n  u2 <- runif(draws)\n# compute R and Theta\n  Theta <- 2*pi*u2\n  R <- sqrt(-2*log(1-u1))\n# finally, X1 and X2 as N(0,1)\n  x1 <- R*cos(Theta)\n  x2 <- R*sin(Theta)\n\n\n# probably need 2 plots, u's,x's\ndf_u <- data.frame(cbind(u1,u2))\n\n\nus_density <- ggplot(df_u, aes(x=u1, y=u2)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\", colour=\"white\") +\n  geom_point(colour = \"pink\", size=0.1) +\n  coord_fixed() +\n  ggtitle(\"Contours of u1 vs u2\")\n\ndf_x <- data.frame(cbind(x1,x2))\nxs_density <- ggplot(df_x, aes(x=x1, y=x2)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\", colour=\"white\") +\n  geom_point(colour = \"pink\", size=0.1,alpha=0.4) +\n  coord_fixed() +\n  ggtitle(\"Contours of x1 vs x2\")\n\ndf_x <- data.frame(xs=c(x1,x2),xlabs=rep(c(\"x1\",\"x2\"),each=draws))\nxs_hist <- ggplot(df_x, aes(x=xs, color=xlabs, fill=xlabs)) +\n  geom_histogram(aes(y=..density..), bins = 60, position=\"identity\", alpha=0.3) +\n  theme_bw()\n\nus_density\n\n\n\nxs_density\n\n\n\nxs_hist\n\n\n\n\nExample 2\nWhat if we wanted y to be somewhere else, have a different spread OR\nhave some correlation? Transform the X’s…i.e. we can (now) get \\[X_1 \\sim N(0,1)\\perp \\!\\!\\! \\perp X_2 \\sim\nN(0,1)\\], but we want:\n\\[\n\\begin{eqnarray}\n\\underline{y} &\\sim&\nN(\\underline{\\mu}_{(2,1)},\\mathbf{\\Sigma}_{(2,2)})\\text{ dimensions\ngiven as subscript} \\\\\n\\tag{10}\n\\underline{y} &=&\n\\mathbf{X}\\mathbf{\\Sigma}^{-\\tfrac{1}{2}}+\\underline{\\mu}\n\\end{eqnarray}\n\\]\nSuppose for instance, we want \\(y_1\\sim\nN(3,0.1), y_2\\sim N(1,2)\\) where cov(\\(y_1,y_2\\))=-0.4.\nDefine \\(\\underline{\\mu}=(3,1)\\) and\n\\(\\Sigma=\\begin{vmatrix}  0.1 & -0.4\n\\\\  -0.4 & 2 \\\\  \\end{vmatrix}\\)\nLooking at the code and plot below, it appears as though our\nlocation, spread and covariance all visible match what we want. Without\nshowing the numbers, the stats match as well.\n\n\n\n\n\n\n",
    "preview": "mcmc/2022-06-14-box-muller-tldr/box-muller-tldr_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-06-20T08:57:44-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "mcmc/2022-06-13-detailed-balance-proof-tldr/",
    "title": "tl;dr Detailed Balance",
    "description": "Detailed balance description and proof for Gibbs and Metropolis-Hastings .",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-13",
    "categories": [
      "MCMC",
      "Detailed Balance",
      "Gibbs",
      "Metropolis",
      "Metropolis-Hastings"
    ],
    "contents": "\n\nContents\nGibbs\nAlgorithm\nProof\n\nMetropolis(-Hastings)\nAlgorithm\nProof\n\n\nShort proof of detailed balance for Gibbs and Metropolis(-Hastings)\nSampling. The general idea is that you need to prove that the forward\nand backward transitions should be equal, ie there is no bias in\ntransition movement.\nThis is summed up as follows:\nForward transition probability: \\(P(x'\\mid x)\\)\nReverse transition probability: \\(P(x\\mid\nx')\\)\nOur claim is if:\n\\[\n\\begin{eqnarray}\n\\tag{1}\n\\Pi_i(x')\\;P_{ij}(x'\\mid x) &=& \\Pi_j \\; P_{ji}(x)(x\n\\mid x') \\text{ then} \\\\\n\\vec{\\Pi} &=& \\{{\\Pi_1, \\Pi_2, \\dots \\Pi_N}\\} \\text{ is\nstationary}\n\\end{eqnarray}\n\\]\nGibbs\nAlgorithm\n\\[\n\\begin{eqnarray}\nStep 1:  \\\\\n\\tag{1}\ny' &\\sim & f(y\\mid x) \\\\\nStep 2:  \\\\\n\\tag{2}\nx' &\\sim & f(x\\mid y')\n\\end{eqnarray}\n\\]\nProof\nWant to prove:\n\\[\n\\tag{3}\nforward\\; transition = backward\\; transition\n\\]\n\\[\n\\begin{eqnarray}\n\\tag{4}\n{\\overbrace {\\textstyle f(x\\mid y)\\;p([x',y']\\mid [x,y])}^{\n{forward\\; direction}}}  &=& f(x,y)\\;{\\overbrace {f(y'\\mid\nx)}^{ {step 1}}}\\; {\\overbrace {\\textstyle f(x'\\mid y')}^{ {step\n2}}}\\\\\n  &=& f(x,y)\\;\n\\frac{f(y',x)}{f(x)}\\frac{f(x',y')}{f(y')} \\text{ Bayes\nRule} \\\\\n  &=& \\frac{f(x,y)}{f(x)}\\;\n\\frac{f(y',x)}{f(y')}f(x',y') \\\\\n  &=& {\\underbrace {\\textstyle f(y\\mid x)}_{ {step 2}}}\\;\n{\\underbrace {\\textstyle f(x\\mid y')}_{ {step 1}}}\\;f(x',y')\n\\text{ Bayes Rule}\\\\\n  &=& p([x,y]\\mid [x',y'])\\;f(x',y') \\\\\n  &=& {\\underbrace {\\textstyle p([x,y]\\mid\n[x',y'])\\;f(x'\\mid y')}_{ {bacward\\; direction}}}\n\\end{eqnarray}\n\\]\nMetropolis(-Hastings)\nMetropolis and Metropolis-Hastings differ in the transition rule. The\nMetropolis-Hastings correction to the Metropolis sampler adds a\ncorrection to account for situations where the sampling distribution is\nnot symetric. Adding the correction term to the below does not change\nthe argument.\nAlgorithm\nMetropolis:\ninit \\(x^{(t=0)}\\)\nfor t in 1:T\npropose \\(x^{\\ast} \\sim g(x^t \\mid\nx^{t-1})\\)\n\\(\\alpha = min(1,\n\\frac{\\Pi(x^{\\ast})}{\\Pi(x^{(t-1)})})\\)\n\\(x^t = \\begin{cases} x^{\\ast} \\text{ w.p.\n} \\alpha \\\\ x^{(t-1)} \\;\\;\\; 1-\\alpha \\end{cases}\\)\n\nProof\nNeed to show\n\\[\n\\begin{equation}\n\\tag{3}\nP_{ij}\\Pi_i = P_{ji}\\Pi_j\n\\end{equation}\n\\]\nWLOG: assume \\(\\Pi_(x') \\le\n\\Pi_(x)\\) for calulating \\(\\alpha\\)\nForward\n\\[\n\\begin{eqnarray}\n\\tag{4}\nP_{ij}(x' \\mid x) &=& {\\overbrace {g(x'\\mid x)}^{ {step\n1}}}\\;\\; {\\overbrace {\\alpha}^{ {step 2}}} \\\\\n  &=& g(x'\\mid x) \\cdot\nmin\\left(1,\\frac{\\Pi(x')}{\\Pi(x)}\\right) \\\\\n  &=& g(x'\\mid x) \\cdot \\frac{\\Pi(x')}{\\Pi(x)}\n\\end{eqnarray}\n\\]\nReverse\n\\[\n\\begin{eqnarray}\n\\tag{5}\nP_{ji}(x \\mid x') &=& {\\overbrace {g(x\\mid x')}^{ {step\n1}}}\\;\\; {\\overbrace {\\alpha}^{ {step 2}}} \\\\\n  &=& g(x\\mid x') \\cdot\nmin\\left(1,\\frac{\\Pi(x)}{\\Pi(x')}\\right) \\\\\n  &=& g(x'\\mid x) \\cdot 1 \\\\\n  &=& g(x'\\mid x)\n\\end{eqnarray}\n\\]\nDetailed Balance\n\\[\n\\begin{eqnarray}\n\\tag{6}\nP_{ij} \\Pi_i &=& P_{ji}\\Pi_j \\\\\ng(x'\\mid x) \\frac{\\Pi (x')}{\\Pi (x)}\\Pi (x) &=& g(x\\mid\nx') \\Pi(x') \\\\\ng(x'\\mid x) \\Pi(x) &=& g(x\\mid x') \\Pi(x')\n\\end{eqnarray}\n\\]\n\n\n\n",
    "preview": {},
    "last_modified": "2022-06-13T20:27:24-04:00",
    "input_file": {}
  },
  {
    "path": "mcmc/2022-06-12-chebychev-tldr/",
    "title": "tl;dr Chebychev Inequality",
    "description": "Chebychev Inequality proof and use.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-12",
    "categories": [
      "MCMC",
      "Chebychev"
    ],
    "contents": "\n\nContents\nProof\nExample\n\nQuick proof and example of use of the Chebychev Inequality.\nSuppose we have \\(x\\sim f(x), g(x) \\gt 0,\n\\epsilon \\gt 0\\). The Chebychev Inequality is written as:\n\\[\n\\begin{equation}\n\\tag{1}\nPr(g(x) \\ge \\epsilon) \\le \\frac{E[g(x)]}{\\epsilon}\n\\end{equation}\n\\]\nProof\n\\[\n\\begin{eqnarray}\n\\tag{2}\nE[g(x)] &=& \\int_{\\Omega_x} g(x) f(x) dx\n\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\text{ :def of expectation}\\\\\n  &\\ge& \\int_{\\{x: g(x)\\ge \\epsilon\\}}g(x) f(x) dx\n\\;\\;\\;\\;\\text{ :limit x}\\\\\n  &\\ge& \\int_{\\{x: g(x)\\ge \\epsilon\\}} \\epsilon f(x) dx\n\\;\\;\\;\\;\\;\\;\\;\\;\\text{ :smallest g(x)=}\\epsilon \\\\\n  &\\ge& \\epsilon Pr(g(x)\\ge \\epsilon)\n\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\text{ :by def of prob}\n\\end{eqnarray}\n\\]\nSlight rearrangment gives desired Chebychev Inequality equation.\nExample\nSay we observe data \\(\\mathfrak D\\)\nwhich was generated by some process \\(f(\\cdot\n)\\) and we want to know \\(Pr(X=\\mathfrak D)\\). We can use Monte Carlo\nto approximate this. How?\n\\[\n\\begin{equation}\n\\frac{\\sum_{x_i \\sim f(\\cdot)} \\mathbb{1}_{\\{x_i = \\mathfrak D\\}}}{N}\n\\end{equation}\n\\] The question may then be, how good is this or how do we\nmeasure. We could use relative error:\n\\[\n\\begin{equation}\n\\frac{\\mid \\frac{\\sum_{x_i \\sim f(\\cdot)} \\mathbb{1}_{\\{x_i = \\mathfrak\nD\\}}}{N} - Pr(X=\\mathfrak D) \\mid }{Pr(X=\\mathfrak D)}\n\\end{equation}\n\\] Or, perhaps, we want a bit more and want to know the\nprobability the error is within some bound:\n\\[\n\\begin{equation}\nPr\\left(\\frac{\\mid \\frac{\\sum_{x_i \\sim f(\\cdot)} \\mathbb{1}_{\\{x_i =\n\\mathfrak D\\}}}{N} - Pr(X=\\mathfrak D) \\mid }{Pr(X=\\mathfrak D)} \\le\n\\epsilon \\right)\n\\end{equation}\n\\]\nNow this is starting to feel like Chebychev. What if we were to\nsquare the inner terms and follow along with Chebychev:\n\\[\n\\begin{eqnarray}\nPr\\left(\\frac{\\mid \\frac{\\sum_{x_i \\sim f(\\cdot)} \\mathbb{1}_{\\{x_i =\n\\mathfrak D\\}}}{N} - Pr(X=\\mathfrak D) \\mid^2 }{Pr(X=\\mathfrak D)^2} \\le\n\\epsilon^2 \\right) &\\le& \\frac{E\\left[\\left(\\frac{\\sum_{x_i \\sim\nf(\\cdot)} \\mathbb{1}_{\\{x_i = \\mathfrak D\\}}}{N} - Pr(X=\\mathfrak\nD)\\right)^2\\right]}{\\epsilon^2 Pr(X=\\mathfrak D)^2} \\\\\n  &\\le& \\frac{Var\\left(\\frac{\\sum_{x_i \\sim f(\\cdot)}\n\\mathbb{1}_{\\{x_i = \\mathfrak D\\}}}{N}\\right)}{\\epsilon^2 Pr(X=\\mathfrak\nD)^2} \\\\\n  &\\le& \\frac{Var\\left(x_i=\\mathfrak D\\right)}{N^2 \\epsilon^2\nPr(X=\\mathfrak D)^2} \\text{ numerator is just iid Bernoulli} \\\\\n  &=& \\frac{\\left(1- Pr(x=\\mathfrak D) \\right) Pr(X=\\mathfrak\nD)} {N\\epsilon^2Pr(X=\\mathfrak D)^2} \\\\\n  &=& \\frac{\\left(1- Pr(x=\\mathfrak D) \\right) }\n{N\\epsilon^2Pr(X=\\mathfrak D)}\n\\end{eqnarray}\n\\] This leads to some insights. As N increases, error decreases.\nAdditionally, if \\(Pr(X=\\mathfrak D)\\)\nis small, error is relatively larger for fixed N. Finally, if we pick\nthe # of successes, then the error rate is fixed by N. This last\nobservation is the Las Vegas alternative to Monte Carlo.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-06-13T20:15:45-04:00",
    "input_file": {}
  },
  {
    "path": "mcmc/2022-06-11-inverse-cdf-tldr/",
    "title": "tl;dr Inverse CDF",
    "description": "Monte Carlo using the Inverse CDF.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-11",
    "categories": [
      "MCMC",
      "Inverse CDF"
    ],
    "contents": "\n\nContents\nProposition\nProof\nExample 1\nExample 2\nExample 3\n\nSummary of the Inverse CDF method for generating draws from a\ndistribution given draws from a random uniform.\nProposition\nThe random variable \\(Y=F^{-1}(u)\\),\nwhere \\(F\\) is a distribution function\nand \\(u\\sim unif(0,1)\\), will have\ndistribution \\(F\\).\nProof\nI like the proof that this is true. It is truly simple:\nLet \\(G_Y(y)\\) be a distribution\nfunction for Y. Then:\n\\[\n\\begin{eqnarray}\n\\tag{1}\nG_Y(\\alpha) &=& Pr(y \\le \\alpha) \\\\\n  &=& Pr(F^{-1}(u) \\le \\alpha) \\\\\n  &=& Pr(u \\le F(\\alpha)) \\\\\n  &=& F(\\alpha)\n\\end{eqnarray}\n\\]\nExample 1\nGenerate samples from \\(x\\sim\nexp(\\lambda)\\) using draws from \\(u\\sim\nunif(0,1)\\).\nStep 1: Find CDF\n\\[\n\\begin{equation}\n\\tag{2}\nF(\\alpha) = \\int_0^{\\alpha} \\lambda e^{-\\lambda x} dx = e^{-\\lambda x}\n\\mid_0^{\\alpha} = 1-e^{\\lambda\\alpha}\n\\end{equation}\n\\]\nStep 2: Find invserse CDF\nlet \\(g=1-e^{\\lambda\\alpha}\\)\n\\[\n\\begin{eqnarray}\n\\tag{3}\ng &=& 1-e^{\\lambda\\alpha} \\\\\ne^{-\\lambda \\alpha}  &=& 1-g \\\\\n\\alpha &=& -\\frac{1}{\\lambda}log(1-g) \\\\\nF^{-1}(\\alpha) &=& -\\frac{1}{\\lambda}log(1-\\alpha)\n\\end{eqnarray}\n\\]\nStep 3: Generate Y\ndraw \\(u_i \\sim unif(0,1)\\), now,\n\\(Y=-\\frac{1}{\\lambda}log(1-u) \\sim\nexp(\\lambda)\\)\nExample 2\nWhat if the desired distribution is discrete? For instance, \\(bern(p)\\).\n\\[\n\\begin{equation}\n\\tag{4}\nx \\sim\n\\begin{cases}\n1 \\text{ with probability } p \\\\\n0 \\text{ with probability } 1-p\n\\end{cases}\n\\end{equation}\n\\] Graphically, this looks like:\n\n\n#for graphing, choose arbitrary p=0.6\np=0.75\n\n# Create empty example plot\nplot(0, 0, col = \"white\", xlab = \"y\", ylab = \"u\", xlim=c(0,2), ylim=c(0,1), xaxt=\"n\", yaxt=\"n\")\naxis(1, at=c(0.5,1.5),labels=c(\"0\",\"1\"), col.axis=\"red\", las=1)\naxis(2, at=c(1-p,p),labels=c(\"1-p\",\"p\"), col.axis=\"red\", las=2)\n# Draw one line\nsegments(x0 = 0, y0 = 1-p, x1 = 1-0.03, y1 = 1-p, col = \"red\",lwd=2)\nsegments(x0 = 1, y0 = p, x1 = 2, y1 = p, col = \"blue\",lwd=2)\nsegments(x0 = 1, y0 = 1-p+0.06, x1 = 1, y1 = p, col = \"black\",lwd=2, lty=\"dotted\")\npoints(1,1-p,pch=1,col=\"red\",cex=2)\npoints(1,p,pch=20,col=\"blue\",cex=2)\ntext(0.5,0.3,\"1-p\")\ntext(1.5,0.8,\"p\")\n\n\n\n\nThis is relatively easy:\nStep 1: draw \\(u_i \\sim\nunif(0,1)\\)\nStep 2:\n\\[\n\\begin{equation}\n\\tag{4}\ny =\n\\begin{cases}\n0 \\text{ if } u \\lt 1-p \\\\\n1 \\text{ otherwise }\n\\end{cases}\n\\end{equation}\n\\]\nExample 3\nAn approximate CDF can also be generated in the same way. Think of\nthis as a discretized continuous random variable.\nSuppose we want to generate \\(y\\sim\nN(0,1)\\).\n\\[\n\\begin{equation}\n\\tag{4}\nf(y_i) =\n\\begin{cases}\nf(y_0) \\text{ if } f(y_0) \\le u \\lt f(y_1) \\\\\nf(y_1) \\text{ if } f(y_1) \\le u \\lt f(y_2) \\\\\nf(y_2) \\text{ if } f(y_2) \\le u \\lt f(y_3) \\\\\n\\vdots\n\\end{cases}\n\\end{equation}\n\\]\nGraphically, this starts to look like:\n\n\n# function for arbitrary pdf\npdf <- function(x){\n  y <- (1/(2*pi))*exp(-0.5*x^2)\n}\npar(mfcol=c(1,2))\n\n## PDF\nplot(0, 0, col = \"white\", xlab = \"\", ylab = \"\", xlim=c(-4,4), ylim=c(0,0.2), main=\"Discretized PDF\")\ncurve(pdf, from=-4, to=4, xlab=\"x\", ylab=\"y\", add=TRUE)\nsegments(x0 = -2, y0 = 0, x1 = -2, y1 = pdf(-2), col = \"red\",lwd=2)\nsegments(x0 = -1.75, y0 = 0, x1 = -1.75, y1 = pdf(-1.75), col = \"red\",lwd=2)\nsegments(x0 = -1.5, y0 = 0, x1 = -1.5, y1 = pdf(-1.5), col = \"red\",lwd=2)\nsegments(x0 = -1.25, y0 = 0, x1 = -1.25, y1 = pdf(-1.25), col = \"red\",lwd=2)\nsegments(x0 = -1, y0 = 0, x1 = -1, y1 = pdf(-1), col = \"red\",lwd=2)\n\n# CDF\nplot(0, 0, col = \"white\", xlab = \"\", ylab = \"u\", xlim=c(-2,0), ylim=c(0,0.2),main=\"Inverse CDF step function\")\nsegments(x0 = -2, y0 = pdf(-2), x1 = -1.75, y1 = pdf(-2), col = \"red\",lwd=2)\nsegments(x0 = -1.75, y0 = pdf(-1.75), x1 = -1.5, y1 = pdf(-1.75), col = \"red\",lwd=2)\nsegments(x0 = -1.5, y0 = pdf(-1.5), x1 = -1.25, y1 = pdf(-1.5), col = \"red\",lwd=2)\nsegments(x0 = -1.25, y0 = pdf(-1.25), x1 = -1, y1 = pdf(-1.25), col = \"red\",lwd=2)\nsegments(x0 = -1, y0 = pdf(-1), x1 = -0.75, y1 = pdf(-1), col = \"red\",lwd=2)\npoints(y = pdf(-2), x = -1.75,pch=1,col=\"red\")\npoints(y = pdf(-1.75), x = -1.5,pch=1,col=\"red\")\npoints(y = pdf(-1.5), x = -1.25,pch=1,col=\"red\")\npoints(y = pdf(-1.25), x = -1,pch=1,col=\"red\")\npoints(y = pdf(-1), x = -0.75,pch=1,col=\"red\")\n\n\n\n\nTo get the final points, they must be normalized by the total of the\ndraws:\n\\[\n\\begin{equation}\nf(y_i) = \\frac{e^{-\\frac{1}{2}y_i^2}}{\\sum_{j=0}^N\ne^{-\\frac{1}{2}y_j^2}}\n\\end{equation}\n\\]\n\n\n\n",
    "preview": "mcmc/2022-06-11-inverse-cdf-tldr/inverse-cdf-tldr_files/figure-html5/bern_graph-1.png",
    "last_modified": "2022-06-12T09:24:59-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "mcmc/2022-06-04-accept-reject-tldr/",
    "title": "tl;dr Accept-Reject",
    "description": "Accept-Reject and Weighted Boostrap algorithms.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-04",
    "categories": [
      "MCMC",
      "Accept-Reject",
      "Weighted Bootstrap",
      "ideas"
    ],
    "contents": "\n\nContents\nAccept-Reject Alrogithm\nExample: Prior \\(\\rightarrow\\) Posterior\n\nIllustrative Example\nfrom article\nPaper example\nusing Weighted Bootstrap\nPaper\nexample using Accept-Reject following burn-in\n\n\nAccept-reject, but following:\n\nSmith and Gelfand, Bayesian statistics without tears: A\nsampling-resampling perspective, 1992 DOI:10.1080/00031305.1992.10475856.\n\nAccept-Reject Alrogithm\nWe want h(\\(\\theta\\)), but have\ng(\\(\\theta\\)). Additionally, we know\n\\(h(\\theta) = \\frac{f(\\theta)}{\\int{f(\\theta)\nd\\theta}}\\) and that there exists some constant \\(M>0\\) where \\(\\frac{f(\\theta)}{g(\\theta)} \\le M\\).\nProcedure:\ngenerate \\(\\theta \\sim\ng(\\theta)\\)\ngenerate \\(u \\sim\n\\text{unif}(0,1)\\)\nif \\(u \\le\n\\frac{f(\\theta)}{Mg(\\theta)}\\) accept (accept with probability\nu), else reject\nrepeat 1-3\nAny accepted \\(\\theta\\) is a random\nvariate from \\(h(\\theta) =\n\\frac{f(\\theta)}{\\int f(\\theta) d\\theta}\\). The proof is\nrelatively simple and given in about 3 lines in the Smith and Gelfand\npaper where I will point you if you need to see it.\nIf we don’t know M:\n\\[\n\\begin{eqnarray}\n\\tag{1}\nM &=& \\int f(\\theta) d\\theta \\approx \\frac{1}{n} \\sum_i \\omega_i\n\\text{ , where } \\\\\n\\tag{2}\n\\omega_i &=& \\frac{f(\\theta_i)}{g(\\theta_i)}\n\\end{eqnarray}\n\\]\nOr alternatively, we could use \\(Weighted\\\nBootstrapping\\) where we draw \\(\\theta^{\\ast}\\) from a realization of \\(\\theta = \\{\\theta_1 \\dots \\theta_n\\}\\).\nFrom this we can calculate: \\[\n\\begin{equation}\n\\tag{3}\nq_i = \\frac{\\omega_i}{\\sum_j \\omega_j} \\text{ ; } \\omega_{[i,j]} \\text{\ngiven in (2)}\n\\end{equation}\n\\]\nNow \\(q_i\\) is our sampling\nprobability for drawing from the \\(\\theta_i\\)’s.\nExample: Prior \\(\\rightarrow\\) Posterior\nWe have prior knowledge in \\(p(\\theta)\\) and want to update our\nknowledge base given new information via the posterior \\(p(\\theta | \\textbf{X})\\).\nIf we let: \\[\n\\begin{eqnarray}\n\\tag{4}\nf_x(\\theta) &=& \\ell(\\theta|\\textbf{X}) p(\\theta)  \\\\\n\\tag{5}\ng(\\theta) &=& p(\\theta) \\text{, further, if we know }\n\\hat{\\theta}_{ML}  \\\\\n\\tag{6}\nM &=& \\ell(\\hat{\\theta|}\\textbf{X})\n\\end{eqnarray}\n\\]\nSo, returning to our procedure, we need to accept with probability\nu\n\\[\n\\begin{eqnarray}\n\\tag{7}\nu &\\le& \\frac{f(\\theta)}{Mg(\\theta)} \\\\\n  &\\le& \\frac{\\ell(\\theta|\\textbf{X})\np(\\theta)}{\\ell(\\hat{\\theta|}\\textbf{X})p(\\theta)} \\\\\n  &\\le&\n\\frac{\\ell(\\theta|\\textbf{X})}{\\ell(\\hat{\\theta|}\\textbf{X})}\n\\end{eqnarray}\n\\]\nIllustrative Example from\narticle\nSmith and Gelfand reworked an example originally given by McCullagh\nand Nelder, Generalized Linear Models, 1989. Essentially, consider two\nconditionally independent (given their parameters) random variables\nobserved 3 times through their sum:\n\\[\n\\begin{eqnarray}\n\\tag{8}\n\\textbf{X}_{i1} &\\sim& Binomial(n_{i1}, \\theta_1) \\\\\n\\tag{9}\n\\textbf{X}_{i2} &\\sim& Binomial(n_{i2}, \\theta_2) \\\\\n\\tag{10}\n\\textbf{Y}_i &=& \\textbf{X}_{i1} + \\textbf{X}_{i2}; i \\in\n\\{1,2,3\\}\n\\end{eqnarray}\n\\]\nLikelihood:\n\\[\n\\begin{equation}\n\\tag{11}\n\\ell(\\theta_1,\\theta_2 | \\textbf{Y}, i \\in \\{1,2,3\\}) = \\prod_{i=1}^{3}\n\\left[\\sum_{j_i} {{n_{i1}}\\choose{j_i}} {{n_{i2}}\\choose{y_i-j_i}} \\ast\n\\theta_1^{j_i}(1-\\theta_1)^{n_{i1}-y_i}\\theta_2^{y_i-j_i}(1-\\theta_2)^{n_{i2}-y_i+j_i}\\right]\n\\end{equation}\n\\]\nAnd are given the following as data:\n\n\n\n\n\ni\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\\(n_{i1}\\)\n\n\n5\n\n\n6\n\n\n4\n\n\n\\(n_{i2}\\)\n\n\n5\n\n\n4\n\n\n6\n\n\n\\(y_i\\)\n\n\n7\n\n\n5\n\n\n6\n\n\nOk, so our data shows observed sums of \\(Y_i =X_1 + X_2\\) going from 5 to 7 given\nthe unknown \\(\\theta_{j \\in\n\\{1,2\\}}\\).\nPaper example using\nWeighted Bootstrap\nFollowing the paper, we will consider priors on both \\(\\theta_1\\) and \\(\\theta_2\\) as uniform(0,1) where the\nauthors generated about 1000 \\(\\theta_1,\n\\theta_2\\) pairs. Following suit:\n\n\nset.seed(15239) # just a random number as seed\nobservations <- 1000\nt1 <- runif(n=observations, min=0, max=1)\nt2 <- runif(n=observations, min=0, max=1)\ntheta_draws <- data.frame(theta1=t1, theta2=t2)\n\n\n\n\n\n\nFigure 1: Theta draws from uniform priors\n\n\n\nWe now sample from these priors using the weighted bootstrap\nproceedure as outlined above. To get at the weights, we need to start by\ncalculating \\(q_i\\). Remembering \\(\\omega_i =\n\\frac{f(\\theta_i)}{g(\\theta_i)}\\), \\(g(\\theta_i) = p(\\theta_i)\\) and \\(f(\\theta_i) =\n\\ell(\\theta_i|\\textbf(X_i))p(\\theta_i)\\)\n\\[\n\\begin{eqnarray}\n\\tag{12}\nq_i &=& \\frac{\\omega_i}{\\sum_{j=1}^n \\omega_j} \\\\\n  &=& \\frac{\\frac{f(\\theta_i)}{g(\\theta_i)}}{\\sum_{j=1}^n\n\\frac{f(\\theta_j)}{g(\\theta_j)}} \\\\\n  &=& \\frac{\\ell(\\theta_i|\\textbf(X_i))}{\\sum_{j=1}^n\n\\ell(\\theta_j|\\textbf(X_j))}\n\\end{eqnarray}\n\\] I have been a little lax in the i, j in this. Here i refers to\nthe ith draw from the priors and j runs across all draws. Note that as\nwe inspect (13), we encounter \\(j_i\\).\nThis represents the possible values of \\(\\textbf{X}_i\\) given the parameters, \\(n_{i1}\\) and \\(n_{i2}\\), and observed \\(y_i\\), so \\(max(0, y_i-n_{i2}) \\le j_i \\le min(n_{i1},\ny_i)\\). Let’s code this up and get our \\(q_i\\)’s.\n\n\nji_min_max <- data.frame(min=c(2,1,0),max=c(5,5,4))\nomega <- rep(1,observations)\nfor(k in 1:observations){\n  for(i in 1:3){\n    ji <- ji_min_max[i,1]\n    temp_omega <- 0\n    while(ji<ji_min_max[i,2]){\n      temp_omega <- temp_omega +\n        choose(test_data[1,i],ji)*choose(test_data[2,i],test_data[3,i]-ji)*\n        (theta_draws$theta1[k]^ji)*((1-theta_draws$theta1[k])^(test_data[1,i]-ji))*\n        (theta_draws$theta2[k]^(test_data[3,i]-ji))*\n        ((1-theta_draws$theta2[k])^(test_data[2,i]-test_data[3,i]+ji))\n      ji <- ji+1\n    }\n    omega[k] <- omega[k] * temp_omega\n  }\n}\nq_i <- omega/sum(omega)\n\n\n\nNow do the draws according to the \\(q_i\\)’s and calc the posterior.\n\n\nthetas_index <- sample(1:observations, size=1000, replace=TRUE, prob=q_i) \nh <- omega[thetas_index]\n\n\n\n\n\n\nFigure 2: Posterior with marginals using Weighted Bootstrap\n\n\n\n\n\n\nFigure 3: Posterior with marginals using Weighted Bootstrap\nas a density\n\n\n\nNote, no point in the above posterior is NOT in the previous plot of\nprior draws. The paper appears to have used a different set of points\nfor the plot of the posterior.\nPaper\nexample using Accept-Reject following burn-in\nEstimate M on the fly and use “burn-in” to iteratively converge on M\nand do a real accept-reject.\n\n\nji_min_max <- data.frame(min=c(2,1,0),max=c(5,5,4))\n#quick funtion to calc f(theta)=likelihood, basically took from above\nlhood <- function(t1=0.5,t2=0.5,tdata=test_data,ji_minimax=ji_min_max){\n  for(i in 1:3){\n    ji <- ji_minimax[i,1]\n    temp_likelihood <- 0\n    current_likelihood <- 1\n    while(ji<ji_minimax[i,2]){\n      temp_likelihood <- temp_likelihood +\n        choose(tdata[1,i],ji)*choose(tdata[2,i],tdata[3,i]-ji)*\n        (t1^ji)*((1-t1)^(tdata[1,i]-ji))*\n        (t2^(tdata[3,i]-ji))*((1-t2)^(tdata[2,i]-tdata[3,i]+ji))\n      ji <- ji+1\n    }\n    current_likelihood <- current_likelihood * temp_likelihood\n  }\n  return(current_likelihood)\n}\n\nstored_thetas <- rbind(data.frame(theta1=0,theta2=0,likelihood=0,u=0,accept=1,M=0),\n                       data.frame(theta1=0,theta2=0,likelihood=0,u=0,accept=1,M=0))\nk <- 2\nprevious_M <- 0\n## actual accept/reject\nwhile(sum(stored_thetas$accept)<10000){\n  k <- k+1\n  # 1. make proposal(s)\n  # 2. generate u from uniform(0,1)\n  stored_thetas <- rbind(stored_thetas,\n                         data.frame(theta1=runif(1,0,1),theta2=runif(1,0,1),\n                              u=runif(1,0,1),likelihood=0,accept=0,M=0))\n  # 3. if u <= f/(Mg) then accept, else reject, repeat\n  \n  stored_thetas$likelihood[k] <- lhood(stored_thetas$theta1[k],\n                                            stored_thetas$theta2[k])\n  # calc running M real quick\n  M <- mean(stored_thetas$likelihood[stored_thetas$accept>0])\n  # accpet or reject?\n  stored_thetas$accept[k] <-\n    ifelse(stored_thetas$u[k]<stored_thetas$likelihood[k]/M,1, 0)\n  # update M if needed, this is for status indicator\n  stored_thetas$M[k] <-\n    ifelse(stored_thetas$accept[k]==1,M,stored_thetas$M[k-1])\n  if(stored_thetas$accept[k]==1){\n    M_change <- stored_thetas$M[k]-stored_thetas$M[k-1]\n  }\n  \n  # little status indicator\n  if((k %% 1000)==0){\n    cat(\"current k: \", k, \" current accepted: \", sum(stored_thetas$accept),\n      \" current/change in M:\", M,\" : \", M_change, \"\\n\",sep=\"\")\n  }\n}\n\n\ncurrent k: 1000 current accepted: 452 current/change in M:0.1967587 : -0.000284144\ncurrent k: 2000 current accepted: 932 current/change in M:0.2024283 : -9.629906e-05\ncurrent k: 3000 current accepted: 1417 current/change in M:0.2009935 : -4.114977e-05\ncurrent k: 4000 current accepted: 1865 current/change in M:0.2008423 : -9.366024e-05\ncurrent k: 5000 current accepted: 2333 current/change in M:0.1992392 : -4.590816e-05\ncurrent k: 6000 current accepted: 2804 current/change in M:0.1992795 : 4.192012e-06\ncurrent k: 7000 current accepted: 3296 current/change in M:0.1997426 : -1.830395e-05\ncurrent k: 8000 current accepted: 3768 current/change in M:0.2011892 : 1.26757e-05\ncurrent k: 9000 current accepted: 4201 current/change in M:0.2017363 : -1.827057e-05\ncurrent k: 10000 current accepted: 4690 current/change in M:0.2014897 : 4.914835e-05\ncurrent k: 11000 current accepted: 5187 current/change in M:0.2015779 : 1.636161e-05\ncurrent k: 12000 current accepted: 5657 current/change in M:0.2017894 : -8.658366e-06\ncurrent k: 13000 current accepted: 6116 current/change in M:0.2009656 : -2.302136e-05\ncurrent k: 14000 current accepted: 6585 current/change in M:0.2010067 : 6.980897e-06\ncurrent k: 15000 current accepted: 7054 current/change in M:0.2017694 : 4.251824e-06\ncurrent k: 16000 current accepted: 7536 current/change in M:0.2019006 : 6.399018e-06\ncurrent k: 17000 current accepted: 8011 current/change in M:0.202628 : -9.512693e-06\ncurrent k: 18000 current accepted: 8475 current/change in M:0.2031243 : 1.733376e-06\ncurrent k: 19000 current accepted: 8943 current/change in M:0.2029498 : 2.093441e-05\ncurrent k: 20000 current accepted: 9452 current/change in M:0.2023991 : 2.138806e-06\ncurrent k: 21000 current accepted: 9901 current/change in M:0.2022406 : -1.338133e-05\n\nstored_thetas <- stored_thetas[-c(1,2),]\ncat(\"final M is: \",M, \"\\n\",sep=\"\")\n\n\nfinal M is: 0.2021795\n\n\n\n\nFigure 4: Stablizing M\n\n\n\n\n\n\nFigure 5: Posterior with density, accpeted only\n\n\n\n\n\n\nFigure 6: Posterior with density, rejected only\n\n\n\nAlternatives (ideas) for a future post?\ndifferent priors\niterate on \\(\\theta\\)’s, ie fix\none, sample other, alternate\nothers … ??\n\n\n\n",
    "preview": "mcmc/2022-06-04-accept-reject-tldr/accept-reject-tldr_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-06-13T20:32:27-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "mcmc/2022-06-13-ar-digression-tldr/",
    "title": "Accept-Reject-digression-tldr",
    "description": "Accept-Reject intuitive description.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-04",
    "categories": [
      "MCMC",
      "Accept-Reject"
    ],
    "contents": "\n\nContents\nExample\n\nSuppose we have an area \\(\\Omega'\\) completely enclosed by\nanother area \\(\\Omega\\) as seen below.\nWe know how to sample from the larger area \\(\\Omega\\) but we really want to sample from\n\\(\\Omega'\\).\n\n\n\nWe can do this via the Accept-Reject algorithm as follows:\nLet\\(g(x) = \\frac{\\mathbb{1}_\\Omega\n(x)}{A(\\Omega)}\\) where we have an indicator for in/out of \\(\\Omega\\) and A is the area defined by \\(\\Omega\\).\nSimilarly, we define our target by:\\(f(x) = \\frac{\\mathbb{1}_\\Omega'\n(x)}{A(\\Omega')}\\)\nThe AR algorithm is then:\ndraw \\(u\\sim unif(0,1)\\)\ndraw \\(x \\sim g(\\cdot)\\)\naccept if \\(u \\le \\frac{f(x)}{Mg(x)} =\n\\frac{A(\\Omega)}{A(\\Omega')}\\frac{\\mathbb{1}_\\Omega'\n(x)}{\\mathbb{1}_\\Omega (x)}\\frac{1}{M}\\). We should pick \\(M=\\frac{A(\\Omega)}{A(\\Omega')}\\).\nExample\nDarts to estimate \\(\\pi\\).\nConsider a circle circumscribed within the bounds of the square, both\ncentered on (x,y)=(0,0). Let the radius of the circle be 1 such that if\nwe focus on the first quadrant, we are looking at a unit square. Within\nthis quadrant, we can form the ratio of the areas as:\n\\[\n\\begin{equation}\n\\frac{\\tfrac{1}{4}A_{circle}}{A_{square}} = \\frac{\\pi r^2}{4r^2} =\n\\frac{\\pi}{4}\n\\end{equation}\n\\] So, if we could measure the area of the circle vs square in\nthis quadrant, we know the ratio will be \\(\\frac{\\pi}{4}\\). So, how can we determine\nthe areas? How about we sample from the unit square and perform\naccept-reject if the points samples fall within the circle?\ndraw \\(u_1 \\sim unif(0,1), u_2\\sim\nunif(0,1)\\)\naccept if \\(\\sqrt{u_1^2 + u_2^2} \\le\n1\\)\n\\(\\pi =\n4*\\frac{accept}{draws}\\)\n\n\nset.seed(189437)\nN <- 1e6\naccept <- rep(0,N)\nu1_draw <- runif(N)\nu2_draw <- runif(N)\nfor(i in 1:N){\n  if(sqrt(u1_draw[i]^2+u2_draw[i]^2)<1){\n    accept[i] <- 1\n  }\n}\nsimpi <- 4*sum(accept)/N\nplot(u1_draw, u2_draw, col=accept+1,pch=20)\ntext(0.4,0.4,paste0(N,\" draws to estimate pi to \",simpi))\n\n\n\n\n\n\n\n",
    "preview": "mcmc/2022-06-13-ar-digression-tldr/ar-digression-tldr_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-06-13T21:51:15-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "mcmc/2022-06-01-monte-carlo-tldr/",
    "title": "tl;dr Monte Carlo",
    "description": "Basic Monte-Carlo description and theory.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [
      "MCMC"
    ],
    "contents": "\n\nContents\nMonte Carlo\nGeneral idea\n\nExample 1\nExample 2\nExample 3\nBias, variance and\nconvergence\nBias\n\n\nMonte-Carlo summary. Much of this is following notes from Scotland\nLemon’s MCMC class in Spring 2017 at Virginia Tech.\nMonte Carlo\nClass or set of algorithms to produce a random and approximate\nsolution to a problem in a \\(\\textbf{fixed}\\) amount of time. As opposed\nto Las Vegas algorithms that produce a solution of fixed tolerance in an\nunknown amount of time.\nMonte Carlo methods rely on sampling \\(iid\\) from the distribution to then compute\nthe estimate. The class and what I am interested in more are random\nwalks where the next sample is dependent on the current sample. This is\nmore aptly described as Markov Chain Monte Carlo.\nGeneral idea\nif \\(x\\sim p(x)\\), where we can\nsample from \\(p(x)\\), but we want \\(g(x)\\), then\n\\[\n\\begin{eqnarray}\n\\tag{1}\nE[g(x)] &=& \\int_{\\Omega_x}g(x)p(x)dx \\\\\n  &\\approx& \\frac{\\sum g(x)}{N} \\text{where }x_i\\sim p(x)\n\\end{eqnarray}\n\\]\nExample 1\nWe want \\(E[u]\\) where \\(u\\sim unif[0,1]\\). The pdf of x is\n\\[\n\\begin{equation}\n\\tag{2}\nx \\sim\n\\begin{cases}\n1 \\text{ if } 0 \\le u \\le 1 \\\\\n0 \\text{ otherwise}\n\\end{cases}\n\\end{equation}\n\\] So we could do this analytically as:\n\\[\n\\begin{equation}\n\\tag{3}\nE[u] = \\int_0^1 u\\;p(u)\\;du = \\frac{u^3}{2} \\mid _0^1 =\n\\frac{1}{2}\\text{ similarly, var}(u)=\\frac{1}{12}\n\\end{equation}\n\\] Alternatively, using Monte-Carlo approximation, we would\nfollow:\ninit \\(u_0 = runif(1)\\)\nfor \\(i=1:N\\)\\(u_i = runif(1)\\)\nend\nNow:\n\\[\n\\begin{eqnarray}\n\\tag{4}\nmean(u) &=& \\frac{\\sum_{i=1}^N u_i}{N} \\approx \\int_0^1\nu\\;p(u)\\;du \\\\\n\\tag{5}\nVar(u) &=& \\frac{\\sum_{i=1}^N (u_i-E[u])^2}{N} \\approx \\int_0^1\n(u_i-E[u])^2\\;p(u)\\;du\n\\end{eqnarray}\n\\]\nQuick try with N going from 100 to 10,000:\n\n\nset.seed(12475)\ndraws <- runif(10000)\nresults <- data.frame(means=rbind(mean(draws[1:100]),mean(draws[1:1000]),mean(draws)),\n                      vars=rbind(var(draws[1:1000]),var(draws[1:100]),var(draws)),\n                      row.names = c(\"100\",\"1,000\",\"1,0000\"))\nkable(results,digits = 4)\n\n\n\n\n\nmeans\n\n\nvars\n\n\n100\n\n\n0.5131\n\n\n0.0848\n\n\n1,000\n\n\n0.4950\n\n\n0.0816\n\n\n1,0000\n\n\n0.5009\n\n\n0.0856\n\n\nLooks like the mean is approaching the desired value of 0.5.\nExample 2\n\\(x\\sim N(\\mu=10, \\sigma^2=1)\\)\nWant \\(E[x^4]\\):\n\\[\n\\begin{equation}\n\\tag{6}\nE[x^4] = \\int_{-\\infty}^{\\infty} x^4\\;p(x)\\;dx =\n\\int_{-\\infty}^{\\infty}x^4\\;\\frac{1}{\\sqrt{2\\pi}}e^{-\\tfrac{(x-E[x])^2}{2}}\\;dx\n= ??\n\\end{equation}\n\\] We may be able to do this integral using some tricks, but\ninstead, perhaps use Monte Carlo:\ninit \\(x_0 = rnorm(10,1)\\)\nfor \\(i=1:N\\)\\(x_i = rnorm(10,1)\\)\nend\nNow:\n\\[\n\\begin{equation}\n\\tag{7}\nE[X^4] \\approx \\frac{\\sum_{x_i\\sim N(10,1)}x_i^4}{N}\n\\end{equation}\n\\]\n\n\nset.seed(12475)\ndraws <- rnorm(10000,10,1)^4\nresults <- data.frame(means=rbind(mean(draws[1:100]),mean(draws[1:1000]),mean(draws)),\n                      row.names = c(\"100\",\"1,000\",\"1,0000\"))\nkable(results,digits = 4)\n\n\n\n\n\nmeans\n\n\n100\n\n\n10258.86\n\n\n1,000\n\n\n10608.94\n\n\n1,0000\n\n\n10615.04\n\n\nIt appears to be converging to what we would hope would be close to\n10k.\nExample 3\n\\(x\\sim exp(\\lambda)\\)\nWant:\n\\(E[e^{sin(x)}]\\) where \\(0 \\le x \\le \\pi\\)\n\\[\n\\begin{eqnarray}\n\\tag{8}\nE[e^{sin(x)}\\mid 0 \\le x \\le \\pi] &=& \\int_0^{\\pi} e^{sin(x)}\n\\lambda e^{-\\lambda x} dx \\\\\n  &=& \\int_0^{-\\infty} \\delta(x)_{[0,\\pi]}e^{sin(x)} \\lambda\ne^{-\\lambda x} dx \\\\\n  &\\approx& \\frac{1}{N}\\sum_{x_i \\sim exp(\\lambda)}\n\\delta(x)_{[0,\\pi]}e^{sin(x)}\n\\end{eqnarray}\n\\]\nThe key here is the N is from samples of \\(x_i\\) that pass the criteria, ie pass the\ndelta function.\nBias, variance and\nconvergence\nCouple things to clean up to close, is the estimate biased and how\ndoes it converge? For this, let’s assume we are looking at\n\\(u\\stackrel{iid}{\\sim}unif(0,1)\\text{;\ni=1..N}\\)\n\\(E[u]\\approx\n\\frac{\\sum_{u_i\\stackrel{iid}{\\sim}unif(0,1)}u_i}{N}=\\hat{M}\\)\nand similar for variance.\nBias\nIs the estimate biased?\n\\[\n\\begin{eqnarray}\n\\tag{8}\nE[\\hat{M}] &=& E\\left[\\frac{\\sum_{i=1}^Nu_i}{N}\\right] \\\\\n  &=& \\frac{\\sum_{i=1}^N E[u_i]}{N} \\\\\n  &=& \\frac{\\sum_{i=1}^N E[u]}{N} \\text{ b/c iid}\\\\\n  &=& E[u] \\\\\n  &=& M\n\\end{eqnarray}\n\\]\n\\[\n\\begin{eqnarray}\n\\tag{9}\nVar[\\hat{M}] &=& Var\\left[\\frac{\\sum_{i=1}^Nu_i}{N}\\right] \\\\\n  &=& \\frac{\\sum_{i=1}^N Var[u_i]}{N^2} \\\\\n  &=& \\frac{\\sum_{i=1}^N Var[u]}{N^2} \\text{ b/c iid}\\\\\n  &=& \\frac{Var[u]}{N} \\\\\n  &\\xrightarrow[]{N\\rightarrow \\infty}& 0\n\\end{eqnarray}\n\\]\nSo our estimate is unbiased with zero variance. Can we say anything\nabout convergence in probability?\n\\[\n\\begin{eqnarray}\n\\tag{10}\nPr(\\mid \\hat{M}-M \\mid \\lt \\epsilon) &=& Pr\\left(\\mid \\hat{M}-M\n\\mid \\lt \\delta \\cdot \\sqrt{V/N}\\right) \\text{ where V=Var(M)} \\\\\n  &=& Pr\\left(\\frac{\\mid \\hat{M}-M \\mid}{\\sqrt{V/N}} \\lt\n\\delta\\right) \\text{note this is }N(0,1)\\lt\\delta\\\\\n  &\\approx& Pr\\left(\\frac{\\mid \\hat{M}-M \\mid}{\\sqrt{\\hat{V}/N}}\n\\lt \\delta\\right) \\text{note }\\hat{V}\\text{ is sample estimate of\nvariance, now this is }t(0,1)\\lt\\delta\n\\end{eqnarray}\n\\]\nAnd by the CLT, we can make probabilistic statements. We also note\nour probabilistic error bound only depends on N through \\(\\sqrt{\\frac{V}{N}}\\approx\\sqrt{\\frac{\\hat{V}}{N}}\\)\nso that for any dimensional problem, the error descreases at the rate of\n\\(N^{-\\tfrac{1}{2}}\\) such that we are\n\\(O(N^{-\\tfrac{1}{2}})\\)\nconvergence.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-06-11T21:43:20-04:00",
    "input_file": {}
  }
]
