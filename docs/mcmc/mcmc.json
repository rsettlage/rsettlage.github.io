[
  {
    "path": "mcmc/2022-06-11-inverse-cdf/",
    "title": "tl;dr Inverse CDF",
    "description": "Monte Carlo using the Inverse CDF.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-11",
    "categories": [
      "MCMC",
      "Inverse CDF"
    ],
    "contents": "\n\nContents\nProposition\nProof\nExample 1\nExample 2\nExample 3\n\nSummary of the Inverse CDF method for generating draws from a\ndistribution given draws from a random uniform.\nProposition\nThe random variable \\(Y=F^{-1}(u)\\),\nwhere \\(F\\) is a distribution function\nand \\(u\\sim unif(0,1)\\), will have\ndistribution \\(F\\).\nProof\nI like the proof that this is true. It is truly simple:\nLet \\(G_Y(y)\\) be a distribution\nfunction for Y. Then:\n\\[\n\\begin{eqnarray}\n\\tag{1}\nG_Y(\\alpha) &=& Pr(y \\le \\alpha) \\\\\n  &=& Pr(F^{-1}(u) \\le \\alpha) \\\\\n  &=& Pr(u \\le F(\\alpha)) \\\\\n  &=& F(\\alpha)\n\\end{eqnarray}\n\\]\nExample 1\nGenerate samples from \\(x\\sim\nexp(\\lambda)\\) using draws from \\(u\\sim\nunif(0,1)\\).\nStep 1: Find CDF\n\\[\n\\begin{equation}\n\\tag{2}\nF(\\alpha) = \\int_0^{\\alpha} \\lambda e^{-\\lambda x} dx = e^{-\\lambda x}\n\\mid_0^{\\alpha} = 1-e^{\\lambda\\alpha}\n\\end{equation}\n\\]\nStep 2: Find invserse CDF\nlet \\(g=1-e^{\\lambda\\alpha}\\)\n\\[\n\\begin{eqnarray}\n\\tag{3}\ng &=& 1-e^{\\lambda\\alpha} \\\\\ne^{-\\lambda \\alpha}  &=& 1-g \\\\\n\\alpha &=& -\\frac{1}{\\lambda}log(1-g) \\\\\nF^{-1}(\\alpha) &=& -\\frac{1}{\\lambda}log(1-\\alpha)\n\\end{eqnarray}\n\\]\nStep 3: Generate Y\ndraw \\(u_i \\sim unif(0,1)\\), now,\n\\(Y=-\\frac{1}{\\lambda}log(1-u) \\sim\nexp(\\lambda)\\)\nExample 2\nWhat if the desired distribution is discrete? For instance, \\(bern(p)\\).\n\\[\n\\begin{equation}\n\\tag{4}\nx \\sim\n\\begin{cases}\n1 \\text{ with probability } p \\\\\n0 \\text{ with probability } 1-p\n\\end{cases}\n\\end{equation}\n\\] Graphically, this looks like:\n\n\n#for graphing, choose arbitrary p=0.6\np=0.75\n\n# Create empty example plot\nplot(0, 0, col = \"white\", xlab = \"y\", ylab = \"u\", xlim=c(0,2), ylim=c(0,1), xaxt=\"n\", yaxt=\"n\")\naxis(1, at=c(0.5,1.5),labels=c(\"0\",\"1\"), col.axis=\"red\", las=1)\naxis(2, at=c(1-p,p),labels=c(\"1-p\",\"p\"), col.axis=\"red\", las=2)\n# Draw one line\nsegments(x0 = 0, y0 = 1-p, x1 = 1-0.03, y1 = 1-p, col = \"red\",lwd=2)\nsegments(x0 = 1, y0 = p, x1 = 2, y1 = p, col = \"blue\",lwd=2)\nsegments(x0 = 1, y0 = 1-p+0.06, x1 = 1, y1 = p, col = \"black\",lwd=2, lty=\"dotted\")\npoints(1,1-p,pch=1,col=\"red\",cex=2)\npoints(1,p,pch=20,col=\"blue\",cex=2)\ntext(0.5,0.3,\"1-p\")\ntext(1.5,0.8,\"p\")\n\n\n\n\nThis is relatively easy:\nStep 1: draw \\(u_i \\sim\nunif(0,1)\\)\nStep 2:\n\\[\n\\begin{equation}\n\\tag{4}\ny =\n\\begin{cases}\n0 \\text{ if } u \\lt 1-p \\\\\n1 \\text{ otherwise }\n\\end{cases}\n\\end{equation}\n\\]\nExample 3\nAn approximate CDF can also be generated in the same way. Think of\nthis as a discretized continuous random variable.\nSuppose we want to generate \\(y\\sim\nN(0,1)\\).\n\\[\n\\begin{equation}\n\\tag{4}\nf(y_i) =\n\\begin{cases}\nf(y_0) \\text{ if } f(y_0) \\le u \\lt f(y_1) \\\\\nf(y_1) \\text{ if } f(y_1) \\le u \\lt f(y_2) \\\\\nf(y_2) \\text{ if } f(y_2) \\le u \\lt f(y_3) \\\\\n\\vdots\n\\end{cases}\n\\end{equation}\n\\]\nGraphically, this starts to look like:\n\n\n# function for arbitrary pdf\npdf <- function(x){\n  y <- (1/(2*pi))*exp(-0.5*x^2)\n}\npar(mfcol=c(1,2))\n\n## PDF\nplot(0, 0, col = \"white\", xlab = \"\", ylab = \"\", xlim=c(-4,4), ylim=c(0,0.2), main=\"Discretized PDF\")\ncurve(pdf, from=-4, to=4, xlab=\"x\", ylab=\"y\", add=TRUE)\nsegments(x0 = -2, y0 = 0, x1 = -2, y1 = pdf(-2), col = \"red\",lwd=2)\nsegments(x0 = -1.75, y0 = 0, x1 = -1.75, y1 = pdf(-1.75), col = \"red\",lwd=2)\nsegments(x0 = -1.5, y0 = 0, x1 = -1.5, y1 = pdf(-1.5), col = \"red\",lwd=2)\nsegments(x0 = -1.25, y0 = 0, x1 = -1.25, y1 = pdf(-1.25), col = \"red\",lwd=2)\nsegments(x0 = -1, y0 = 0, x1 = -1, y1 = pdf(-1), col = \"red\",lwd=2)\n\n# CDF\nplot(0, 0, col = \"white\", xlab = \"\", ylab = \"u\", xlim=c(-2,0), ylim=c(0,0.2),main=\"Inverse CDF step function\")\nsegments(x0 = -2, y0 = pdf(-2), x1 = -1.75, y1 = pdf(-2), col = \"red\",lwd=2)\nsegments(x0 = -1.75, y0 = pdf(-1.75), x1 = -1.5, y1 = pdf(-1.75), col = \"red\",lwd=2)\nsegments(x0 = -1.5, y0 = pdf(-1.5), x1 = -1.25, y1 = pdf(-1.5), col = \"red\",lwd=2)\nsegments(x0 = -1.25, y0 = pdf(-1.25), x1 = -1, y1 = pdf(-1.25), col = \"red\",lwd=2)\nsegments(x0 = -1, y0 = pdf(-1), x1 = -0.75, y1 = pdf(-1), col = \"red\",lwd=2)\npoints(y = pdf(-2), x = -1.75,pch=1,col=\"red\")\npoints(y = pdf(-1.75), x = -1.5,pch=1,col=\"red\")\npoints(y = pdf(-1.5), x = -1.25,pch=1,col=\"red\")\npoints(y = pdf(-1.25), x = -1,pch=1,col=\"red\")\npoints(y = pdf(-1), x = -0.75,pch=1,col=\"red\")\n\n\n\n\nTo get the final points, they must be normalized by the total of the\ndraws:\n\\[\n\\begin{equation}\nf(y_i) = \\frac{e^{-\\frac{1}{2}y_i^2}}{\\sum_{j=0}^N\ne^{-\\frac{1}{2}y_j^2}}\n\\end{equation}\n\\]\n\n\n\n",
    "preview": "mcmc/2022-06-11-inverse-cdf/inverse-cdf_files/figure-html5/bern_graph-1.png",
    "last_modified": "2022-06-12T09:10:33-04:00",
    "input_file": "inverse-cdf.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "mcmc/2022-06-04-accept-reject-tldr/",
    "title": "tl;dr Accept-Reject",
    "description": "Accept-Reject and Weighted Boostrap algorithms.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-04",
    "categories": [
      "MCMC",
      "Accept-Reject",
      "Weighted Bootstrap"
    ],
    "contents": "\n\nContents\nAccept-Reject Alrogithm\nExample: Prior \\(\\rightarrow\\) Posterior\n\nIllustrative Example\nfrom article\nPaper example\nusing Weighted Bootstrap\nPaper\nexample using Accept-Reject following burn-in\n\n\nAccept-reject, but following:\n\nSmith and Gelfand, Bayesian statistics without tears: A\nsampling-resampling perspective, 1992 DOI:10.1080/00031305.1992.10475856.\n\nAccept-Reject Alrogithm\nWe want h(\\(\\theta\\)), but have\ng(\\(\\theta\\)). Additionally, we know\n\\(h(\\theta) = \\frac{f(\\theta)}{\\int{f(\\theta)\nd\\theta}}\\) and that there exists some constant \\(M>0\\) where \\(\\frac{f(\\theta)}{g(\\theta)} \\le M\\).\nProcedure:\ngenerate \\(\\theta \\sim\ng(\\theta)\\)\ngenerate \\(u \\sim\n\\text{unif}(0,1)\\)\nif \\(u \\le\n\\frac{f(\\theta)}{Mg(\\theta)}\\) accept (accept with probability\nu), else reject\nrepeat 1-3\nAny accepted \\(\\theta\\) is a random\nvariate from \\(h(\\theta) =\n\\frac{f(\\theta)}{\\int f(\\theta) d\\theta}\\). The proof is\nrelatively simple and given in about 3 lines in the Smith and Gelfand\npaper where I will point you if you need to see it.\nIf we don’t know M:\n\\[\n\\begin{eqnarray}\n\\tag{1}\nM &=& \\int f(\\theta) d\\theta \\approx \\frac{1}{n} \\sum_i \\omega_i\n\\text{ , where } \\\\\n\\tag{2}\n\\omega_i &=& \\frac{f(\\theta_i)}{g(\\theta_i)}\n\\end{eqnarray}\n\\]\nOr alternatively, we could use \\(Weighted\\\nBootstrapping\\) where we draw \\(\\theta^{\\ast}\\) from a realization of \\(\\theta = \\{\\theta_1 \\dots \\theta_n\\}\\).\nFrom this we can calculate: \\[\n\\begin{equation}\n\\tag{3}\nq_i = \\frac{\\omega_i}{\\sum_j \\omega_j} \\text{ ; } \\omega_{[i,j]} \\text{\ngiven in (2)}\n\\end{equation}\n\\]\nNow \\(q_i\\) is our sampling\nprobability for drawing from the \\(\\theta_i\\)’s.\nExample: Prior \\(\\rightarrow\\) Posterior\nWe have prior knowledge in \\(p(\\theta)\\) and want to update our\nknowledge base given new information via the posterior \\(p(\\theta | \\textbf{X})\\).\nIf we let: \\[\n\\begin{eqnarray}\n\\tag{4}\nf_x(\\theta) &=& \\ell(\\theta|\\textbf{X}) p(\\theta)  \\\\\n\\tag{5}\ng(\\theta) &=& p(\\theta) \\text{, further, if we know }\n\\hat{\\theta}_{ML}  \\\\\n\\tag{6}\nM &=& \\ell(\\hat{\\theta|}\\textbf{X})\n\\end{eqnarray}\n\\]\nSo, returning to our procedure, we need to accept with probability\nu\n\\[\n\\begin{eqnarray}\n\\tag{7}\nu &\\le& \\frac{f(\\theta)}{Mg(\\theta)} \\\\\n  &\\le& \\frac{\\ell(\\theta|\\textbf{X})\np(\\theta)}{\\ell(\\hat{\\theta|}\\textbf{X})p(\\theta)} \\\\\n  &\\le&\n\\frac{\\ell(\\theta|\\textbf{X})}{\\ell(\\hat{\\theta|}\\textbf{X})}\n\\end{eqnarray}\n\\]\nIllustrative Example from\narticle\nSmith and Gelfand reworked an example originally given by McCullagh\nand Nelder, Generalized Linear Models, 1989. Essentially, consider two\nconditionally independent (given their parameters) random variables\nobserved 3 times through their sum:\n\\[\n\\begin{eqnarray}\n\\tag{8}\n\\textbf{X}_{i1} &\\sim& Binomial(n_{i1}, \\theta_1) \\\\\n\\tag{9}\n\\textbf{X}_{i2} &\\sim& Binomial(n_{i2}, \\theta_2) \\\\\n\\tag{10}\n\\textbf{Y}_i &=& \\textbf{X}_{i1} + \\textbf{X}_{i2}; i \\in\n\\{1,2,3\\}\n\\end{eqnarray}\n\\]\nLikelihood:\n\\[\n\\begin{equation}\n\\tag{11}\n\\ell(\\theta_1,\\theta_2 | \\textbf{Y}, i \\in \\{1,2,3\\}) = \\prod_{i=1}^{3}\n\\left[\\sum_{j_i} {{n_{i1}}\\choose{j_i}} {{n_{i2}}\\choose{y_i-j_i}} \\ast\n\\theta_1^{j_i}(1-\\theta_1)^{n_{i1}-y_i}\\theta_2^{y_i-j_i}(1-\\theta_2)^{n_{i2}-y_i+j_i}\\right]\n\\end{equation}\n\\]\nAnd are given the following as data:\n\n\n\n\n\ni\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\\(n_{i1}\\)\n\n\n5\n\n\n6\n\n\n4\n\n\n\\(n_{i2}\\)\n\n\n5\n\n\n4\n\n\n6\n\n\n\\(y_i\\)\n\n\n7\n\n\n5\n\n\n6\n\n\nOk, so our data shows observed sums of \\(Y_i =X_1 + X_2\\) going from 5 to 7 given\nthe unknown \\(\\theta_{j \\in\n\\{1,2\\}}\\).\nPaper example using\nWeighted Bootstrap\nFollowing the paper, we will consider priors on both \\(\\theta_1\\) and \\(\\theta_2\\) as uniform(0,1) where the\nauthors generated about 1000 \\(\\theta_1,\n\\theta_2\\) pairs. Following suit:\n\n\nset.seed(15239) # just a random number as seed\nobservations <- 1000\nt1 <- runif(n=observations, min=0, max=1)\nt2 <- runif(n=observations, min=0, max=1)\ntheta_draws <- data.frame(theta1=t1, theta2=t2)\n\n\n\n\n\n\nFigure 1: Theta draws from uniform priors\n\n\n\nWe now sample from these priors using the weighted bootstrap\nproceedure as outlined above. To get at the weights, we need to start by\ncalculating \\(q_i\\). Remembering \\(\\omega_i =\n\\frac{f(\\theta_i)}{g(\\theta_i)}\\), \\(g(\\theta_i) = p(\\theta_i)\\) and \\(f(\\theta_i) =\n\\ell(\\theta_i|\\textbf(X_i))p(\\theta_i)\\)\n\\[\n\\begin{eqnarray}\n\\tag{12}\nq_i &=& \\frac{\\omega_i}{\\sum_{j=1}^n \\omega_j} \\\\\n  &=& \\frac{\\frac{f(\\theta_i)}{g(\\theta_i)}}{\\sum_{j=1}^n\n\\frac{f(\\theta_j)}{g(\\theta_j)}} \\\\\n  &=& \\frac{\\ell(\\theta_i|\\textbf(X_i))}{\\sum_{j=1}^n\n\\ell(\\theta_j|\\textbf(X_j))}\n\\end{eqnarray}\n\\] I have been a little lax in the i, j in this. Here i refers to\nthe ith draw from the priors and j runs across all draws. Note that as\nwe inspect (13), we encounter \\(j_i\\).\nThis represents the possible values of \\(\\textbf{X}_i\\) given the parameters, \\(n_{i1}\\) and \\(n_{i2}\\), and observed \\(y_i\\), so \\(max(0, y_i-n_{i2}) \\le j_i \\le min(n_{i1},\ny_i)\\). Let’s code this up and get our \\(q_i\\)’s.\n\n\nji_min_max <- data.frame(min=c(2,1,0),max=c(5,5,4))\nomega <- rep(1,observations)\nfor(k in 1:observations){\n  for(i in 1:3){\n    ji <- ji_min_max[i,1]\n    temp_omega <- 0\n    while(ji<ji_min_max[i,2]){\n      temp_omega <- temp_omega +\n        choose(test_data[1,i],ji)*choose(test_data[2,i],test_data[3,i]-ji)*\n        (theta_draws$theta1[k]^ji)*((1-theta_draws$theta1[k])^(test_data[1,i]-ji))*\n        (theta_draws$theta2[k]^(test_data[3,i]-ji))*\n        ((1-theta_draws$theta2[k])^(test_data[2,i]-test_data[3,i]+ji))\n      ji <- ji+1\n    }\n    omega[k] <- omega[k] * temp_omega\n  }\n}\nq_i <- omega/sum(omega)\n\n\n\nNow do the draws according to the \\(q_i\\)’s and calc the posterior.\n\n\nthetas_index <- sample(1:observations, size=1000, replace=TRUE, prob=q_i) \nh <- omega[thetas_index]\n\n\n\n\n\n\nFigure 2: Posterior with marginals using Weighted Bootstrap\n\n\n\n\n\n\nFigure 3: Posterior with marginals using Weighted Bootstrap\nas a density\n\n\n\nNote, no point in the above posterior is NOT in the previous plot of\nprior draws. The paper appears to have used a different set of points\nfor the plot of the posterior.\nPaper\nexample using Accept-Reject following burn-in\nEstimate M on the fly and use “burn-in” to iteratively converge on M\nand do a real accept-reject.\n\n\nji_min_max <- data.frame(min=c(2,1,0),max=c(5,5,4))\n#quick funtion to calc f(theta)=likelihood, basically took from above\nlhood <- function(t1=0.5,t2=0.5,tdata=test_data,ji_minimax=ji_min_max){\n  for(i in 1:3){\n    ji <- ji_minimax[i,1]\n    temp_likelihood <- 0\n    current_likelihood <- 1\n    while(ji<ji_minimax[i,2]){\n      temp_likelihood <- temp_likelihood +\n        choose(tdata[1,i],ji)*choose(tdata[2,i],tdata[3,i]-ji)*\n        (t1^ji)*((1-t1)^(tdata[1,i]-ji))*\n        (t2^(tdata[3,i]-ji))*((1-t2)^(tdata[2,i]-tdata[3,i]+ji))\n      ji <- ji+1\n    }\n    current_likelihood <- current_likelihood * temp_likelihood\n  }\n  return(current_likelihood)\n}\n\nstored_thetas <- rbind(data.frame(theta1=0,theta2=0,likelihood=0,u=0,accept=1,M=0),\n                       data.frame(theta1=0,theta2=0,likelihood=0,u=0,accept=1,M=0))\nk <- 2\nprevious_M <- 0\n## actual accept/reject\nwhile(sum(stored_thetas$accept)<10000){\n  k <- k+1\n  # 1. make proposal(s)\n  # 2. generate u from uniform(0,1)\n  stored_thetas <- rbind(stored_thetas,\n                         data.frame(theta1=runif(1,0,1),theta2=runif(1,0,1),\n                              u=runif(1,0,1),likelihood=0,accept=0,M=0))\n  # 3. if u <= f/(Mg) then accept, else reject, repeat\n  \n  stored_thetas$likelihood[k] <- lhood(stored_thetas$theta1[k],\n                                            stored_thetas$theta2[k])\n  # calc running M real quick\n  M <- mean(stored_thetas$likelihood[stored_thetas$accept>0])\n  # accpet or reject?\n  stored_thetas$accept[k] <-\n    ifelse(stored_thetas$u[k]<stored_thetas$likelihood[k]/M,1, 0)\n  # update M if needed, this is for status indicator\n  stored_thetas$M[k] <-\n    ifelse(stored_thetas$accept[k]==1,M,stored_thetas$M[k-1])\n  if(stored_thetas$accept[k]==1){\n    M_change <- stored_thetas$M[k]-stored_thetas$M[k-1]\n  }\n  \n  # little status indicator\n  if((k %% 1000)==0){\n    cat(\"current k: \", k, \" current accepted: \", sum(stored_thetas$accept),\n      \" current/change in M:\", M,\" : \", M_change, \"\\n\",sep=\"\")\n  }\n}\n\n\ncurrent k: 1000 current accepted: 452 current/change in M:0.1967587 : -0.000284144\ncurrent k: 2000 current accepted: 932 current/change in M:0.2024283 : -9.629906e-05\ncurrent k: 3000 current accepted: 1417 current/change in M:0.2009935 : -4.114977e-05\ncurrent k: 4000 current accepted: 1865 current/change in M:0.2008423 : -9.366024e-05\ncurrent k: 5000 current accepted: 2333 current/change in M:0.1992392 : -4.590816e-05\ncurrent k: 6000 current accepted: 2804 current/change in M:0.1992795 : 4.192012e-06\ncurrent k: 7000 current accepted: 3296 current/change in M:0.1997426 : -1.830395e-05\ncurrent k: 8000 current accepted: 3768 current/change in M:0.2011892 : 1.26757e-05\ncurrent k: 9000 current accepted: 4201 current/change in M:0.2017363 : -1.827057e-05\ncurrent k: 10000 current accepted: 4690 current/change in M:0.2014897 : 4.914835e-05\ncurrent k: 11000 current accepted: 5187 current/change in M:0.2015779 : 1.636161e-05\ncurrent k: 12000 current accepted: 5657 current/change in M:0.2017894 : -8.658366e-06\ncurrent k: 13000 current accepted: 6116 current/change in M:0.2009656 : -2.302136e-05\ncurrent k: 14000 current accepted: 6585 current/change in M:0.2010067 : 6.980897e-06\ncurrent k: 15000 current accepted: 7054 current/change in M:0.2017694 : 4.251824e-06\ncurrent k: 16000 current accepted: 7536 current/change in M:0.2019006 : 6.399018e-06\ncurrent k: 17000 current accepted: 8011 current/change in M:0.202628 : -9.512693e-06\ncurrent k: 18000 current accepted: 8475 current/change in M:0.2031243 : 1.733376e-06\ncurrent k: 19000 current accepted: 8943 current/change in M:0.2029498 : 2.093441e-05\ncurrent k: 20000 current accepted: 9452 current/change in M:0.2023991 : 2.138806e-06\ncurrent k: 21000 current accepted: 9901 current/change in M:0.2022406 : -1.338133e-05\n\nstored_thetas <- stored_thetas[-c(1,2),]\ncat(\"final M is: \",M, \"\\n\",sep=\"\")\n\n\nfinal M is: 0.2021795\n\n\n\n\nFigure 4: Stablizing M\n\n\n\n\n\n\nFigure 5: Posterior with density, accpeted only\n\n\n\n\n\n\nFigure 6: Posterior with density, rejected only\n\n\n\nAlternatives for a future post?\ndifferent priors\niterate on \\(\\theta\\)’s, ie fix\none, sample other, alternate\nothers … ??\n\n\n\n",
    "preview": "mcmc/2022-06-04-accept-reject-tldr/accept-reject-tldr_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-06-11T21:06:33-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "mcmc/2022-06-01-monte-carlo-tldr/",
    "title": "tl;dr Monte Carlo",
    "description": "Basic Monte-Carlo description and theory.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [
      "MCMC"
    ],
    "contents": "\n\nContents\nMonte Carlo\nGeneral idea\n\nExample 1\nExample 2\nExample 3\nBias, variance and\nconvergence\nBias\n\n\nMonte-Carlo summary. Much of this is following notes from Scotland\nLemon’s MCMC class in Spring 2017 at Virginia Tech.\nMonte Carlo\nClass or set of algorithms to produce a random and approximate\nsolution to a problem in a \\(\\textbf{fixed}\\) amount of time. As opposed\nto Las Vegas algorithms that produce a solution of fixed tolerance in an\nunknown amount of time.\nMonte Carlo methods rely on sampling \\(iid\\) from the distribution to then compute\nthe estimate. The class and what I am interested in more are random\nwalks where the next sample is dependent on the current sample. This is\nmore aptly described as Markov Chain Monte Carlo.\nGeneral idea\nif \\(x\\sim p(x)\\), where we can\nsample from \\(p(x)\\), but we want \\(g(x)\\), then\n\\[\n\\begin{eqnarray}\n\\tag{1}\nE[g(x)] &=& \\int_{\\Omega_x}g(x)p(x)dx \\\\\n  &\\approx& \\frac{\\sum g(x)}{N} \\text{where }x_i\\sim p(x)\n\\end{eqnarray}\n\\]\nExample 1\nWe want \\(E[u]\\) where \\(u\\sim unif[0,1]\\). The pdf of x is\n\\[\n\\begin{equation}\n\\tag{2}\nx \\sim\n\\begin{cases}\n1 \\text{ if } 0 \\le u \\le 1 \\\\\n0 \\text{ otherwise}\n\\end{cases}\n\\end{equation}\n\\] So we could do this analytically as:\n\\[\n\\begin{equation}\n\\tag{3}\nE[u] = \\int_0^1 u\\;p(u)\\;du = \\frac{u^3}{2} \\mid _0^1 =\n\\frac{1}{2}\\text{ similarly, var}(u)=\\frac{1}{12}\n\\end{equation}\n\\] Alternatively, using Monte-Carlo approximation, we would\nfollow:\ninit \\(u_0 = runif(1)\\)\nfor \\(i=1:N\\)\\(u_i = runif(1)\\)\nend\nNow:\n\\[\n\\begin{eqnarray}\n\\tag{4}\nmean(u) &=& \\frac{\\sum_{i=1}^N u_i}{N} \\approx \\int_0^1\nu\\;p(u)\\;du \\\\\n\\tag{5}\nVar(u) &=& \\frac{\\sum_{i=1}^N (u_i-E[u])^2}{N} \\approx \\int_0^1\n(u_i-E[u])^2\\;p(u)\\;du\n\\end{eqnarray}\n\\]\nQuick try with N going from 100 to 10,000:\n\n\nset.seed(12475)\ndraws <- runif(10000)\nresults <- data.frame(means=rbind(mean(draws[1:100]),mean(draws[1:1000]),mean(draws)),\n                      vars=rbind(var(draws[1:1000]),var(draws[1:100]),var(draws)),\n                      row.names = c(\"100\",\"1,000\",\"1,0000\"))\nkable(results,digits = 4)\n\n\n\n\n\nmeans\n\n\nvars\n\n\n100\n\n\n0.5131\n\n\n0.0848\n\n\n1,000\n\n\n0.4950\n\n\n0.0816\n\n\n1,0000\n\n\n0.5009\n\n\n0.0856\n\n\nLooks like the mean is approaching the desired value of 0.5.\nExample 2\n\\(x\\sim N(\\mu=10, \\sigma^2=1)\\)\nWant \\(E[x^4]\\):\n\\[\n\\begin{equation}\n\\tag{6}\nE[x^4] = \\int_{-\\infty}^{\\infty} x^4\\;p(x)\\;dx =\n\\int_{-\\infty}^{\\infty}x^4\\;\\frac{1}{\\sqrt{2\\pi}}e^{-\\tfrac{(x-E[x])^2}{2}}\\;dx\n= ??\n\\end{equation}\n\\] We may be able to do this integral using some tricks, but\ninstead, perhaps use Monte Carlo:\ninit \\(x_0 = rnorm(10,1)\\)\nfor \\(i=1:N\\)\\(x_i = rnorm(10,1)\\)\nend\nNow:\n\\[\n\\begin{equation}\n\\tag{7}\nE[X^4] \\approx \\frac{\\sum_{x_i\\sim N(10,1)}x_i^4}{N}\n\\end{equation}\n\\]\n\n\nset.seed(12475)\ndraws <- rnorm(10000,10,1)^4\nresults <- data.frame(means=rbind(mean(draws[1:100]),mean(draws[1:1000]),mean(draws)),\n                      row.names = c(\"100\",\"1,000\",\"1,0000\"))\nkable(results,digits = 4)\n\n\n\n\n\nmeans\n\n\n100\n\n\n10258.86\n\n\n1,000\n\n\n10608.94\n\n\n1,0000\n\n\n10615.04\n\n\nIt appears to be converging to what we would hope would be close to\n10k.\nExample 3\n\\(x\\sim exp(\\lambda)\\)\nWant:\n\\(E[e^{sin(x)}]\\) where \\(0 \\le x \\le \\pi\\)\n\\[\n\\begin{eqnarray}\n\\tag{8}\nE[e^{sin(x)}\\mid 0 \\le x \\le \\pi] &=& \\int_0^{\\pi} e^{sin(x)}\n\\lambda e^{-\\lambda x} dx \\\\\n  &=& \\int_0^{-\\infty} \\delta(x)_{[0,\\pi]}e^{sin(x)} \\lambda\ne^{-\\lambda x} dx \\\\\n  &\\approx& \\frac{1}{N}\\sum_{x_i \\sim exp(\\lambda)}\n\\delta(x)_{[0,\\pi]}e^{sin(x)}\n\\end{eqnarray}\n\\]\nThe key here is the N is from samples of \\(x_i\\) that pass the criteria, ie pass the\ndelta function.\nBias, variance and\nconvergence\nCouple things to clean up to close, is the estimate biased and how\ndoes it converge? For this, let’s assume we are looking at\n\\(u\\stackrel{iid}{\\sim}unif(0,1)\\text{;\ni=1..N}\\)\n\\(E[u]\\approx\n\\frac{\\sum_{u_i\\stackrel{iid}{\\sim}unif(0,1)}u_i}{N}=\\hat{M}\\)\nand similar for variance.\nBias\nIs the estimate biased?\n\\[\n\\begin{eqnarray}\n\\tag{8}\nE[\\hat{M}] &=& E\\left[\\frac{\\sum_{i=1}^Nu_i}{N}\\right] \\\\\n  &=& \\frac{\\sum_{i=1}^N E[u_i]}{N} \\\\\n  &=& \\frac{\\sum_{i=1}^N E[u]}{N} \\text{ b/c iid}\\\\\n  &=& E[u] \\\\\n  &=& M\n\\end{eqnarray}\n\\]\n\\[\n\\begin{eqnarray}\n\\tag{9}\nVar[\\hat{M}] &=& Var\\left[\\frac{\\sum_{i=1}^Nu_i}{N}\\right] \\\\\n  &=& \\frac{\\sum_{i=1}^N Var[u_i]}{N^2} \\\\\n  &=& \\frac{\\sum_{i=1}^N Var[u]}{N^2} \\text{ b/c iid}\\\\\n  &=& \\frac{Var[u]}{N} \\\\\n  &\\xrightarrow[]{N\\rightarrow \\infty}& 0\n\\end{eqnarray}\n\\]\nSo our estimate is unbiased with zero variance. Can we say anything\nabout convergence in probability?\n\\[\n\\begin{eqnarray}\n\\tag{10}\nPr(\\mid \\hat{M}-M \\mid \\lt \\epsilon) &=& Pr\\left(\\mid \\hat{M}-M\n\\mid \\lt \\delta \\cdot \\sqrt{V/N}\\right) \\text{ where V=Var(M)} \\\\\n  &=& Pr\\left(\\frac{\\mid \\hat{M}-M \\mid}{\\sqrt{V/N}} \\lt\n\\delta\\right) \\text{note this is }N(0,1)\\lt\\delta\\\\\n  &\\approx& Pr\\left(\\frac{\\mid \\hat{M}-M \\mid}{\\sqrt{\\hat{V}/N}}\n\\lt \\delta\\right) \\text{note }\\hat{V}\\text{ is sample estimate of\nvariance, now this is }t(0,1)\\lt\\delta\n\\end{eqnarray}\n\\]\nAnd by the CLT, we can make probabilistic statements. We also note\nour probabilistic error bound only depends on N through \\(\\sqrt{\\frac{V}{N}}\\approx\\sqrt{\\frac{\\hat{V}}{N}}\\)\nso that for any dimensional problem, the error descreases at the rate of\n\\(N^{-\\tfrac{1}{2}}\\) such that we are\n\\(O(N^{-\\tfrac{1}{2}})\\)\nconvergence.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-06-11T21:43:20-04:00",
    "input_file": {}
  }
]
