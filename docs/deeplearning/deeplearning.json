[
  {
    "path": "deeplearning/2022-11-04-fun-with-h2o/",
    "title": "Fun with H2O and LIME",
    "description": "Quick posting showing use of H2O.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-11-04",
    "categories": [
      "DeepLearning",
      "H2O",
      "LIME"
    ],
    "contents": "\n\nContents\nEDA\nFeature Engineering\nModeling with H2O\nAutoml\nManually specifying a model method\n\nExplore results\nModel performance\nModel prediction\n\n\nThis is a quick post to show use of H2O as an automl tool. As stated in the docs (https://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html), H2O is an open source, distributed, fast and scalable machine learning platform written in Java. It supports many different supervised and unsupervised algorithms. I am interested in how optimum the generated models are. Here I will just demonstrate the use of the platform, compare to a quick GLM, and will end by showing LIME for explanation of model outcomes.\nFor the demo dataset, I am using the Palmer Penguins dataset. This dataset has 344 measurements of penguin physical characteristics along with labels for sex, species, location and year of the measurement. For this demonstration, I will see what H2O can accomplish in predicting sex from the other attributes. First, some EDA just to get a sense of what the dataset looks like:\nEDA\n\n\n# love the skimr package, quick look shows some missing values and distributions\nskim(palmerpenguins::penguins)\n\nTable 1: Data summary\nName\npalmerpenguins::penguins\nNumber of rows\n344\nNumber of columns\n8\n_______________________\n\nColumn type frequency:\n\nfactor\n3\nnumeric\n5\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n# get dataset reformatted and filtered, dont want to deal with missing data\npenguins_new <- palmerpenguins::penguins %>% \n  select(-year) %>%\n  filter(complete.cases(.)) %>%\n  mutate_if(is.factor, as_factor)\n\n\npenguins_new %>%\n  ggplot(aes(x=species, y=(bill_length_mm))) +\n  geom_violin() +\n  geom_jitter(aes(color=sex), alpha=0.4, width = 0.1) + \n  facet_grid(~island) +\n  labs(title=\"bill length by species, island, sex\")\n\n\npenguins_new %>%\n  ggplot(aes(x=species, y=(bill_depth_mm))) +\n  geom_violin() +\n  geom_jitter(aes(color=sex), alpha=0.4, width = 0.1) + \n  facet_grid(~island) +\n  labs(title=\"bill depth by species, island, sex\")\n\n\npenguins_new %>%\n  ggplot(aes(x=species, y=(flipper_length_mm))) +\n  geom_violin() +\n  geom_jitter(aes(color=sex), alpha=0.4, width = 0.1) + \n  facet_grid(~island) +\n  labs(title=\"flipper length by species, island, sex\")\n\n\npenguins_new %>%\n  ggplot(aes(x=species, y=(body_mass_g))) +\n  geom_violin() +\n  geom_jitter(aes(color=sex), alpha=0.4, width = 0.1) + \n  facet_grid(~island) +\n  labs(title=\"body by species, island, sex\")\n\n\npairs(x=penguins_new %>% select_if(is.numeric), \n      pch=20)\n\n\n\nFeature Engineering\nThis is where an SME would add the secret sauce. I am definitely NOT a penguin biologist, but I am going to pretend I know bill volume is important and can be computed by assuming the bill is a pyramid with volume calculated as \\[volume = \\frac{1}{3} \\ast length \\ast depth^2\\] I am also going to center and scale the numeric predictors. Bill_volume might actually do some good in separating sexes, so let’s keep it. This will make it’s way into the recipe in the next section.\n\n\npenguins_new <- penguins_new %>%\n  mutate(bill_volume = 1/3 * bill_length_mm * bill_depth_mm^2)\n\npenguins_new %>%\n  ggplot(aes(x=species, y=(bill_volume))) +\n  geom_violin() +\n  geom_jitter(aes(color=sex), alpha=0.4, width = 0.1) + \n  facet_grid(~island) +\n  labs(title=\"bill volume by species, island, sex\")\n\n\n\nModeling with H2O\nHere we will do the normal 10-fold cross validation and have our holdout set for publication metrics. To get this, we will use rsample::initial_split to create the holdout set of 10% of the data. Additionally, I am creating a recipe for the data processing to assist in later predictions using new data.\n\n\n# Put most of the data into the training set, want the other set more like a true\n# test set as H2O is doing cross validation so the validation data set is pulled \n# from the training dataset\n\nset.seed(34547)\npenguins_split <- initial_split(\n  palmerpenguins::penguins %>% filter(complete.cases(.)), \n  prop = 0.90)\n# now do the split\ntrain_data <- training(penguins_split)\ntest_data  <- testing(penguins_split)\n\n# just want to center and scale, leave factors to h2o.\n# feature engineering step should be in recipe so that new data is captured\n# so adding the bill_volume calc here\npengiun_recipe <- recipe(sex~., data=train_data) %>%\n  step_select(-year) %>%\n  step_factor2string() %>%\n  step_string2factor() %>%\n  step_mutate(bill_volume = 1/3 * bill_length_mm * bill_depth_mm^2) %>%\n  step_center(all_numeric_predictors()) %>%\n  step_scale(all_numeric_predictors())\n\n# printing the recipe gives a nice summary \npengiun_recipe\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          7\n\nOperations:\n\nVariables selected -year\nCharacter variables from <none>\nFactor variables from <none>\nVariable mutation for 1 / 3 * bill_length_mm * bill_de...\nCentering for all_numeric_predictors()\nScaling for all_numeric_predictors()\n\n# don't forget to bake the data\n\ntrain_data_baked <- pengiun_recipe %>% \n    prep() %>% \n    bake(train_data) \n\ntest_data_baked <- pengiun_recipe %>% \n    prep() %>% \n    bake(test_data) \n\n\nWith our data prepped, we are now ready to proceed to the modeling stage. In this case, we are creating a model to predict sex and have a labeled dataset for training. In machine learning speak, this is a supervised learning classification problem. H2O supports many different algorithms for performing this task. We are going to run H2O’s AutoML to get an idea of how it does in an automated algorithm search and follow that up by running the h2o.glm method to see what we can do manually.\nAutoml\nH2O’s automl method is an attempt at a completely hands off machine learning excersize. H2O will create models using tree based, deep learning and regression methods. It will run until a user specified time limit or the number of models built reaches the user specified limit. By default, it will use 5-fold cross-validation. I am going to specify a 20 min time limit, change the cross-validation strategy to 10-fold, and set the seed for reproducibility.\n\n\ntrain_h2o <- as.h2o(train_data_baked)\ntest_h2o  <- as.h2o(test_data_baked)\n\ny <- \"sex\"\nx <- setdiff(names(train_h2o), y)\n\nautoml_models_h2o <- h2o.automl(\n    x = x,\n    y = y,\n    training_frame   = train_h2o,\n    max_runtime_secs = 1200, \n    nfolds           = 10,\n    seed = 38981\n)\n\n\nFrom the automl training, we can look at the leaderboard and get a quick sense of how it did by looking at the confusion matrix for our holdout set. In the below, we see the StackedEnsemble and DeepLearning methods performed best using AUC as the metric. I want to focus on the DeepLearning model so will extract the top DeepLearning model.\n\n\nautoml_models_h2o@leaderboard\n\n                                                 model_id       auc\n1 StackedEnsemble_BestOfFamily_7_AutoML_1_20221110_205708 0.9723863\n2 StackedEnsemble_BestOfFamily_6_AutoML_1_20221110_205708 0.9721625\n3   DeepLearning_grid_1_AutoML_1_20221110_205708_model_11 0.9715807\n4    DeepLearning_grid_1_AutoML_1_20221110_205708_model_4 0.9715360\n5 StackedEnsemble_BestOfFamily_4_AutoML_1_20221110_205708 0.9709094\n6   DeepLearning_grid_1_AutoML_1_20221110_205708_model_12 0.9708199\n    logloss     aucpr mean_per_class_error      rmse        mse\n1 0.2083160 0.9655582           0.07109291 0.2427961 0.05894995\n2 0.2132914 0.9653595           0.06429019 0.2455755 0.06030734\n3 0.2500111 0.9702776           0.07075725 0.2529788 0.06399825\n4 0.2410589 0.9713846           0.08458647 0.2603849 0.06780029\n5 0.2176247 0.9617852           0.07086914 0.2462841 0.06065588\n6 0.2179888 0.9703479           0.08096133 0.2485852 0.06179461\n\n[166 rows x 7 columns] \n\n# grab first model hash\nbest_model <- automl_models_h2o@leaderboard %>% \n  as_tibble() %>%\n  filter(str_detect(model_id,\"DeepLearning\")) %>%\n  slice(1)\nbest_model\n\n# A tibble: 1 × 7\n  model_id                      auc logloss aucpr mean_…¹  rmse    mse\n  <chr>                       <dbl>   <dbl> <dbl>   <dbl> <dbl>  <dbl>\n1 DeepLearning_grid_1_AutoML… 0.972   0.250 0.970  0.0708 0.253 0.0640\n# … with abbreviated variable name ¹​mean_per_class_error\n\n# save the results in its own object\nbest_model_results <- h2o.getModel(paste0(best_model[1]))\n\n\nManually specifying a model method\nSuppose, we are interested specifically in a GLM, H2O allows one to create only the GLM models using the glm method. This allows us to fine tune the model. For instance, in the below I specify lambda = 0 to turn off regularization and again use 10-fold cross validation.\n\n\npengiun_glm <- h2o.glm(family = \"binomial\",\n                       x = x,\n                       y = y,\n                       training_frame = train_h2o,\n                       nfolds = 10,\n                       lambda = 0.0,\n                       seed = 58931)\n\n\nExplore results\nExploring H2O model results is facilitated through a bunch of helper functions. Here I will show functions for looking at performance, prediction and explainability.\nModel performance\nModel performance is a highly technical discussion I am avoiding here. What I instead want to highlight is how to get to the performance metrics H2O gives access to. First, for classification problems like our example, the confusion matrix is a good first indicator of performance.\nAutoML best model:\n\n\nh2o.confusionMatrix(best_model_results)\n\nConfusion Matrix (vertical: actual; across: predicted)  for max f1 @ threshold = 0.862739508209633:\n       female male    Error    Rate\nfemale    146    1 0.006803  =1/147\nmale        1  151 0.006579  =1/152\nTotals    147  152 0.006689  =2/299\n\nGLM model:\n\n\nh2o.confusionMatrix(pengiun_glm)\n\nConfusion Matrix (vertical: actual; across: predicted)  for max f1 @ threshold = 0.463943952801159:\n       female male    Error     Rate\nfemale    136   11 0.074830  =11/147\nmale        7  145 0.046053   =7/152\nTotals    143  156 0.060201  =18/299\n\nAdditionally, given a trained model object, depending on the metric desired, one would use the metric method or retrieve the value from a derived performance object. For classification, generally you would operate on the performance object. In this example, incorrect predictions in either direction are equally undesirable such that the metrics we may be concerned with are F1, accuracy or AUC.\n\n\n# make performance objects\nbest_model_performance <- h2o.performance(best_model_results)\nglm_performance <- h2o.performance(pengiun_glm)\n\n# F1, just retrieving max irrespective of threshold\nbest_model_F1 <- max(h2o.F1(best_model_performance)$f1)\nglm_F1 <- max(h2o.F1(glm_performance)$f1)\n\n# accuracy, just retrieving max irrespective of threshold\nbest_model_accuracy <- max(h2o.accuracy(best_model_performance)$accuracy)\nglm_accuracy <- max(h2o.accuracy(glm_performance)$accuracy)\n\n# AUC\nbest_model_auc <- h2o.auc(best_model_performance)\nglm_auc <- h2o.auc(glm_performance)\n\nresults <- as.data.frame(cbind(F1 = c(best_model_F1, glm_F1), \n                               Accuracy = c(best_model_accuracy, glm_accuracy), \n                               AUC = c(best_model_auc, glm_auc)))\nrownames(results) <- c(\"autoML\", \"GLM\")\nknitr::kable(round(results, 3), caption = \"Classification metrics\")\n\nTable 2: Classification metrics\n\nF1\nAccuracy\nAUC\nautoML\n0.993\n0.993\n0.999\nGLM\n0.942\n0.940\n0.977\n\nModel prediction\nThe goal of modeling is to create a model that can predict on new data. H2O offers a method to give predictions on new data. Let’s make the predictions and plot the confusion matrix on this. Could have done it using H2O’s confusionMatrix function, but in preperation for LIME, let’s grab the predictions first for autoML and then the GLM:.\n\n\n# make some quick predictions to see how we did\nautoml_best_model_predictions <- \n  h2o.predict(best_model_results, newdata = test_h2o) %>% \n  as_tibble() %>% \n  bind_cols(\n    test_data_baked %>% select(sex)\n    ) \n\nglm_predictions <- \n  h2o.predict(pengiun_glm, newdata = test_h2o) %>% \n  as_tibble() %>% \n  bind_cols(\n    test_data_baked %>% select(sex)\n    ) \n\nboth_predictions <-\n  bind_cols(automl_best_model_predictions[,1:3],\n            glm_predictions)\n\nnames(both_predictions) <- c(paste0(\"automl_\",names(automl_best_model_predictions[,1:3])), \n         paste0(\"glm_\",names(glm_predictions[1:3])),\"sex\")\n\nboth_predictions <- both_predictions %>%\n  select(sex, contains(\"predict\"), everything())\n\nboth_predictions %>% \n  yardstick::conf_mat(sex, automl_predict) %>% \n  autoplot(type=\"heatmap\") + labs(title=\"autoML confusion\")\n\n\nboth_predictions %>% \n  yardstick::conf_mat(sex, glm_predict) %>% \n  autoplot(type=\"heatmap\") + labs(title=\"GLM confusion\")\n\n\n\nFrom this, it looks like the GLM performs better on new data. This suggests there may be some over fitting. We can look at the learning curve for the top model. When we do this, it does indeed appear as though the model was overfit as evident by the increasing logloss for the CV training datasets starting around epoc 1000.\n\n\nh2o.learning_curve_plot(best_model_results)\n\n\n\nModel explainability\nIn many cases, explaining a model is important, for instance, in mechanistic studies or in model improvement efforts. H2O offers a single function for a global look at model factor importance, explain. Limiting to the classification example, the output includes a confusion matrix, variable importance plots and partial dependence plots as show below. Each of these and more can be generated through individual calls. For the autoML leader:\n\n\nh2o.explain(best_model_results, test_h2o)\n\n\n\nConfusion Matrix\n================\n\n> Confusion matrix shows a predicted class vs an actual class.\n\n\n\nDeepLearning_grid_1_AutoML_1_20221110_205708_model_11\n-----------------------------------------------------\n\n|  | female | male | Error | Rate\n|:---:|:---:|:---:|:---:|:---:|\n| **female** |15 | 3 | 0.166666666666667 |  =3/18 | \n| **male** |0 | 16 | 0 |  =0/16 | \n| **Totals** |15 | 19 | 0.0882352941176471 |  =3/34 | \n\n\nVariable Importance\n===================\n\n> The variable importance plot shows the relative importance of the most important variables in the model.\n\n\n\nPartial Dependence Plots\n========================\n\n> Partial dependence plot (PDP) gives a graphical depiction of the marginal effect of a variable on the response. The effect of a variable is measured in change in the mean response. PDP assumes independence between the feature for which is the PDP computed and the rest.\n\n\nFrom this, it appears species and bill length are the top variables leading to assignment of sex. Note that sex=male is a positive outcome, so response is 1 in the continuous plots.\nExplanations for the glm model:\n\n\nh2o.explain(pengiun_glm, test_h2o)\n\n\n\nConfusion Matrix\n================\n\n> Confusion matrix shows a predicted class vs an actual class.\n\n\n\nGLM_model_R_1668131819232_38796\n-------------------------------\n\n|  | female | male | Error | Rate\n|:---:|:---:|:---:|:---:|:---:|\n| **female** |18 | 0 | 0 |  =0/18 | \n| **male** |1 | 15 | 0.0625 |  =1/16 | \n| **Totals** |19 | 15 | 0.0294117647058824 |  =1/34 | \n\n\nVariable Importance\n===================\n\n> The variable importance plot shows the relative importance of the most important variables in the model.\n\n\n\nPartial Dependence Plots\n========================\n\n> Partial dependence plot (PDP) gives a graphical depiction of the marginal effect of a variable on the response. The effect of a variable is measured in change in the mean response. PDP assumes independence between the feature for which is the PDP computed and the rest.\n\n\nThe partial dependence plots for the continuous features look a lot more certain as the data approaches the extremes, ie large bill_volume values suggest with high probability a male penguin.\nFeature importance and LIME\nThe interesting features are often the ones where the predictions are incorrect. To look at feature importance on individual predictions, H2O does offer methods for tree based algorithms, but not currently on regression or deep learning models. For this, I am turning to LIME for explanation of individual observations. To use LIME, you first build an explainer using the model and training data, then create an explanation of the data of interest. The explaination uses permutations of the observations variable values to get an idea of the local influence of the variables.\nFirst, let’s remember what our prediction set is along with a filter for incorrect predictions.\n\n\nboth_predictions\n\n# A tibble: 34 × 7\n   sex    automl_predict glm_predict automl…¹ automl…² glm_f…³ glm_m…⁴\n   <fct>  <fct>          <fct>          <dbl>    <dbl>   <dbl>   <dbl>\n 1 female female         female      1.00e+ 0 4.96e- 6 6.04e-1 0.396  \n 2 male   male           male        9.78e-65 1   e+ 0 6.59e-3 0.993  \n 3 male   female         female      1.00e+ 0 1.27e- 4 7.74e-1 0.226  \n 4 male   male           male        8.56e- 8 1.00e+ 0 3.81e-2 0.962  \n 5 female female         female      1   e+ 0 2.50e-28 9.94e-1 0.00637\n 6 male   male           male        9.16e-11 1.00e+ 0 8.86e-4 0.999  \n 7 female female         female      1.00e+ 0 4.41e- 6 8.69e-1 0.131  \n 8 male   male           male        4.75e-11 1.00e+ 0 1.39e-1 0.861  \n 9 female female         female      1   e+ 0 5.89e-24 9.57e-1 0.0434 \n10 female female         female      1.00e+ 0 6.61e- 7 8.93e-1 0.107  \n# … with 24 more rows, and abbreviated variable names ¹​automl_female,\n#   ²​automl_male, ³​glm_female, ⁴​glm_male\n\nboth_predictions %>% \n  mutate_if(is.factor, as.character) %>%\n  filter(!(sex == automl_predict) | !(sex == glm_predict))\n\n# A tibble: 4 × 7\n  sex    automl_predict glm_predict automl_f…¹ autom…² glm_f…³ glm_m…⁴\n  <chr>  <chr>          <chr>            <dbl>   <dbl>   <dbl>   <dbl>\n1 male   female         female        1.00     1.27e-4   0.774  0.226 \n2 female male           female        0.000153 1.00e+0   0.557  0.443 \n3 female male           female        0.0117   9.88e-1   0.623  0.377 \n4 female male           female        0.00211  9.98e-1   0.952  0.0481\n# … with abbreviated variable names ¹​automl_female, ²​automl_male,\n#   ³​glm_female, ⁴​glm_male\n\nNow on to the autoML DeepLearning leader, let’s look at data point 3 which is incorrectly predicted by both the DL and GLM models.\n\n\ntest_data %>% \n  slice(3) %>% \n  mutate(bill_volume = 1/3 * bill_length_mm * bill_depth_mm^2) %>%\n  glimpse()\n\nRows: 1\nColumns: 9\n$ species           <fct> Adelie\n$ island            <fct> Biscoe\n$ bill_length_mm    <dbl> 37.7\n$ bill_depth_mm     <dbl> 18.7\n$ flipper_length_mm <int> 180\n$ body_mass_g       <int> 3600\n$ sex               <fct> male\n$ year              <int> 2007\n$ bill_volume       <dbl> 4394.438\n\nLooking back at the plots, this is a smaller bird, suggesting perhaps why the algorithm would have difficulties.\n\n\n## ok, now for the fun, lets look at what the importance of each feature is\n## build the explainer\nexplainer_penguins_autoML <- train_data_baked %>% \n  select(-sex) %>% \n  lime::lime(\n        model         = best_model_results,\n        bin_continous = TRUE,\n        n_bins        = 4,\n        quantile_bins = TRUE\n)\n#summary(explainer_penguins)\n\n# explain a data point, should look at one it failed on\nexplanation_autoML <- test_data_baked %>% \n  slice(3) %>% \n  select(-sex) %>%\n  lime::explain(\n    explainer = explainer_penguins_autoML,\n    n_labels = 1,\n    #labels = \"female\",\n    n_features = 4,\n    n_permutations = 5000,\n    kernel_width = 0.75\n)\n\n# plot the importance in explaining the decision\nlime::plot_features(explanation_autoML)\n\n\n# can do it for many predictions\nexplanations_autoML <- test_data_baked %>% slice(1:20) %>% select(-sex) %>%\n  lime::explain(\n      explainer = explainer_penguins_autoML,\n      n_labels = 1,\n      n_features = 8,\n      #n_permutations = 5000,\n      kernel_width = 0.9\n)\nlime::plot_explanations(explanations_autoML)\n\n\n\nLooking at the variable importance plot shows bill length and body mass contributed to the assignment as female while species contradicted the assignment. Looking at the heatmap shows body mass and species=Adelie contributed the most to assignment of sex in the first 20 test cases.\nOn to the GLM model:\n\n\n## ok, now for the fun, lets look at what the importance of each feature is\n## build the explainer\nexplainer_penguins_glm <- train_data_baked %>% \n  select(-sex) %>% \n  lime::lime(\n        model         = pengiun_glm,\n        bin_continous = TRUE,\n        n_bins        = 4,\n        quantile_bins = TRUE\n)\n#summary(explainer_penguins)\n\n# explain a data point\nexplanation_glm <- test_data_baked %>% slice(3) %>% select(-sex) %>%\n  lime::explain(\n    explainer = explainer_penguins_glm,\n    n_labels = 1,\n    #labels = \"female\",\n    n_features = 4,\n    n_permutations = 5000,\n    kernel_width = 0.75\n)\n\n# plot the importance in explaining the decision\nlime::plot_features(explanation_glm)\n\n\n# can do it for many predictions\nexplanations_glm <- test_data_baked %>% slice(1:20) %>% select(-sex) %>%\n  lime::explain(\n      explainer = explainer_penguins_glm,\n      n_labels = 1,\n      n_features = 8,\n      #n_permutations = 5000,\n      kernel_width = 0.9\n)\nlime::plot_explanations(explanations_glm)\n\n\n\n\n\n\n",
    "preview": "deeplearning/2022-11-04-fun-with-h2o/fun-with-h2o_files/figure-html5/eda-stage-1.png",
    "last_modified": "2022-11-11T09:28:07-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "deeplearning/",
    "title": "DeepLearning Inspiration",
    "description": "Details of why DeepLearning for me.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [
      "DeepLearning",
      "Perceptron"
    ],
    "contents": "\n\nContents\nPerceptron\nInputs\nWeights\nZ\nActivation function\nOutputs\n\nLearning\nLoss function\nGradient descent\n\nExample 1: linear model\nExample 2: binary\nclassification\nMulticlass perceptrons\nMultilayer Perceptrons\n\n\nI like computer simulations. That is like dumb science though. What\nif the computer could actually learn and make decisions. Woah. Perhaps\nthat is a little too Terminator for where we are at currently, but, how\nfar away is that? Probably not terribly far off. As with the MCMC\ncollection, I am going to start at the start of my understanding and see\nwhere I get. In the realm of Deep Learning, I particularly like\nadversarial networks and reinforcement learning so will likely spend\nmore time on those.\nHere, I am going to start with what I see as the motivation for\nDeepLearning, biology and the perceptron. A particularly good coffee\ntable resource is:\n\n\n\nGoodFellow\n@book{Goodfellow-et-al-2016,\n    title={Deep Learning},\n    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},\n    publisher={MIT Press},\n    note={\\url{http://www.deeplearningbook.org}},\n    year={2016}\n}\nMuch of AI/Machine Learning/Deep Learning history is steeped in\nreplicating nature, specifically the functions of the brain. Drilling\ndown into the brain, we get to neurons. Neurons take input from\ndendrites, pass these as signals through the axon, which are then\ntransmitted through synapses to the dendrites of another neuron.\nModelling the functional behavior of neurons is a feat. Enter the\nperceptron.\nWiki neuron\nPerceptron\nThe Wiki for\nPerceptron’s is pretty complete and I will just quote it:\n\nIn machine learning, the perceptron is an algorithm for supervised\nlearning of binary classifiers. A binary classifier is a function which\ncan decide whether or not an input, represented by a vector of numbers,\nbelongs to some specific class. It is a type of linear classifier,\ni.e. a classification algorithm that makes its predictions based on a\nlinear predictor function combining a set of weights with the feature\nvector.\n\nSo, the perceptron is essentially an over simplified model of our\nunderstanding of neurons. The perceptron is an algorithm that can be\ntuned to perform classification tasks. Since we are simplifying, let’s\ndraw the neuron using input/output labels as our new perceptron.\n\n\n\nFigure 1: Simple perceptron.\n\n\n\nAbove, in our over simplified neuron, we see the components of our\nperceptron are inputs, x’s, importance weights, w’s, an activation\nfunction, f(z), and output, y. We will talk through these parts and then\nimplement this in a simple learning model.\nInputs\nIn our perceptron understanding of neurons, we accept inputs as the\nstart to our algorithm. The inputs can be any type of data, for\ninstance, continuous values such as height, weight, or width, or even\ndiscrete values such as counts or class memberships such as word labels\nin text analytics. When we think of these inputs in our neuronal\nunderstanding, they will often be combined with a bias as in the\naugmented image below. In the neuron, the bias is considered a threshold\nvalue below which the neuron will not “fire” or activate. In our\nperceptron, this is limiting to the case of binary classification,\nuseful, but not complete in that we can use the perceptron for tasks\nother than binary classification as we will see below.\n\n\n\nFigure 2: Perceptron with bias drawn with draw.io.\n\n\n\nWeights\nThese are the things we need, the parameters of the model. In a\nlinear models class, these would be our \\(\\beta\\)’s. The weights are numerical values\nthat indicate the importance of the specific input dimension, ie \\(x_i\\). The perceptron learning algorithm\nwill learn these through iteration, likely using some permutation of\ngradient descent. As mentioned above, we are adding a bias to the\nalgorithm. This is functionally equivalent to an intercept in a linear\nmodel. I have labeled it as “b” and given it a weight, \\(w_0\\), it is convenient to assume b=1 and\nadd this as a dimension to our data as \\(x_0\\).\nZ\nWe need a function to combine the data with the appropriate weights.\nThis is generally given the sybmol “z” or in some figures the symbol for\nsum: \\(\\sum\\). Setting the bias \\(x_0 = 1\\) and learning the associate weight\n(\\(w_0\\)) leaves us with:\n\\[\n\\begin{equation}\n\\tag{1}\n\\textbf{z} = \\sum_i w_i \\ast x_i = \\textbf{w}\\cdot\\textbf{x}\n\\end{equation}\n\\]\nActivation function\nThe activation function, \\(f(z)\\)\ncan take on many forms. In it’s simplest form, it is simply the\nidentity, ie \\(f(z)=z\\). This\neffectively makes the perceptron a linear model. Turning to\nclassification, the activation function becomes the Heavyside step\nfunction, or a mapping \\(z\\) to\n(0,1).\n\\[\n\\begin{equation}\n\\tag{2}\nf(z) =\n\\begin{cases}\n1 \\text{ if } z = \\textbf{w} \\cdot \\textbf{x} > 0 \\\\\n0 \\text{ otherwise}\n\\end{cases}\n\\end{equation}\n\\]\nActivation functions are a varied and active area of research. Common\nactivation functions in neural networks include ReLU, sigmoid, and tanh\namong others. Choice of activation function depends highly on the goals\nof the algorithm and will be discussed in its own future post. Here I\nwill simply give the sigmoid activation function and state that it is\nappropriate and useful in categorical settings where a probability is\ndesired. The sigmoid function looks like:\n\\[\n\\begin{equation}\n\\tag{3}\nf(z) = \\frac{1}{1+e^{-z}} = \\frac{1}{1+e^{-\\textbf{w}\\cdot\\textbf{x}}}\n\\equiv \\sigma(z)\n\\end{equation}\n\\] It is useful to note that \\(\\textbf{w}\\cdot\\textbf{x} \\in\n[-\\infty,\\infty]\\) such that \\(f(z) \\in\n[0,1]\\). For those of you that have studied logistic regression,\nthis should look familiar. In neural network diagrams, you will often\nsee the sigmoid activation as \\(\\sigma(z)\\).\nOutputs\nThe output of the perceptron is our decision. If using the step\nfunction given in (2), the decision may be something as simple as is the\nimage a cat (+1) or not a cat (0). Turning to linear regression, the\noutput is our z’s, or y’s if that is more familiar.\nLearning\nI was hoping to skip this for now, but want to go through an example,\nso will need to hit on both scoring a result and improving the score.\nEssentially, what we are hitting on is the perceptron receives data,\napplies weights, adds them according to \\(z\\), and finally calculates the function\n\\(f(z)\\) to create an output \\(y\\). This output can be a binary (0,1),\ncategorical discrete (0,1,2,…), or a continuous value on some range\n[0,1]. We often (always?) are fitting some known data. Using the known\ndata, we can score how well the current settings on weight fit the data.\nWe do this via a score function often called a cost or loss function in\nAI/machine learning speak. If we can score our result, we should be able\nto improve our score. We do this through iterative updates, often using\na variant of gradient descent and back propagation.\nLoss function\nThe loss function is some measure of how good/bad the model performs\nbased on data. I am going to leave most of this discussion for a\ndifferent post and just give two here: MSE or L\\(_2\\) error and binary cross entropy.\nMSE\nMSE, L\\(_2\\), or mean squared error\nis a measure of error well suited for continuous data. It is calculated\nexactly as the name suggests, take the mean of the square of the\nerror.\\[\n\\begin{eqnarray}\n\\tag{4}\nMSE &=& \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 \\\\\n  &=& \\frac{1}{n} \\sum_{i=1}^n (y_i -\n\\hat{\\textbf{w}}\\cdot\\textbf{x}_i)^2\n\\end{eqnarray}\n\\] Remembering that in the above \\(y =\nf(z) = \\textbf{w}\\cdot\\textbf{x}\\). The hat \\(\\hat{}\\) signifies this is an estimated\nvalue, ie the current output of the perceptron using the current values\nof weights. The last line is simply noting the \\(x_i\\) are likely vectors representing the\ninclusion of the bias as an x and perhaps multiple dimensions to the\ndata. Note that MSE is always positive and gets smaller as the\nprediction and true values converge.\nBinary Cross Entropy\nOften we are looking to discriminate between categories, cat vs dog,\nhigh vs medium vs low, safe vs risky, etc. In the general case, there\ncan be many categories. The loss function is effectively a probability\ndistance. In the case of a binary choice:\n\\[\n\\begin{equation}\n\\tag{5}\nLoss = -\\frac{1}{n}\\sum_{i}^n y_i log(\\hat{y}_i) +\n(1-y_i)log(1-\\hat{y}_i)\n\\end{equation}\n\\] In this case, the labels, \\(y_i\\)’s will be 0 or 1 indicating which\nclass the data point belongs to and the \\(\\hat{y}\\)’s should be considered a\nprobability of the data point belonging to the 1-class. Note that only\none of the two terms will be active based on the actual label and also\nthat the log will always be negative because \\(0 \\le \\hat{y}_i \\le 1\\), hence the “-” out\nfront to ensure we have a positive value. Our goal is to minimize the\nloss.\nGradient descent\nOK, we can calculate an error or loss, how do we do better? We could\ntake random steps and start to get an idea of what the loss surface\nlooks like, but that seems like a good way to compute for ever (not a\nbad thing if I am making pretty pictures along the way ;) ). Instead, we\nwill use a little calculus to figure out in which direction we should\nstep. Remembering from calculus, if we compute the gradient, we will\nhave an indication of slope at the point evaluated.\n\\[\n\\begin{equation}\n\\tag{6}\nw_j^{(t)} = w_j^{(t-1)} - \\lambda \\ast \\nabla_{w_j} Loss(w_j)\n\\end{equation}\n\\]\nThinking of this in terms of a linear model, our cost function is\noften MSE given above in (4), we need to compute the gradient:\n\\[\n\\begin{equation}\n\\tag{7}\n\\nabla_{w_j} Loss(w_j) = \\nabla_{w_j} \\left[\\frac{1}{n} \\sum_{i=1}^n\n(y_i - \\hat{\\textbf{w}}\\cdot\\textbf{x}_i)^2\\right]\n\\end{equation}\n\\]\nFor a simple linear model, we can simplify our thoughts a little and\nthink of \\(\\textbf{w}\\cdot\\textbf{x}\\)\nas being \\(mx + b\\).\n\\[\n\\begin{eqnarray}\n\\tag{8}\n\\nabla_{w_{[b,m]}}Loss(w_{[b,m]}) &=& \\nabla_{w_{[b,m]}}\n\\left[\\frac{1}{n} \\sum_{i=1}^n (y_i - (mx_i+b))^2\\right] \\\\\n\\tag{9}\n\\nabla_{w_{b}}Loss(w_b) &=& \\frac{-2}{n} \\sum_{i=1}^n (y_i -\n(mx_i+b)) \\\\\n\\tag{10}\n\\nabla_{w_{m}}Loss(w_m) &=& \\frac{-2}{n} \\sum_{i=1}^n x_i(y_i -\n(mx_i+b))\n\\end{eqnarray}\n\\] For binary cross entropy:\n\\[\n\\begin{eqnarray}\n\\tag{11}\n\\nabla_{w_{j}}Loss(w_j) &=& \\nabla_{w_{j}}\n\\left[-\\frac{1}{n}\\sum_{i}^n y_i log(\\hat{y}_i) +\n(1-y_i)log(1-\\hat{y}_i)\\right] \\\\\n  && \\text{subsituting in (3)} \\\\\n  &=& \\frac{2}{n} \\sum_{i=1}^n x_i(y_i - \\sigma(z)) \\\\\n\\end{eqnarray}\n\\]\nExample 1: linear model\nWe have gone way too long without data. :)\nFirst, let’s get some data:\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n## create X\nobservations = 50 \nx = np.matrix(range(observations))+1\nones = np.matrix(np.ones(observations))\nX = np.hstack([np.matrix(ones).T, x.T])\n\n# create Y\ntrue_weights = np.matrix([[10],[3]])\nnoise = np.matrix(np.random.uniform(-10,10, size=(observations,))).T\nY = np.matmul(X,true_weights) + noise\n\n# take a peak at our data\nfig1, ax1 = plt.subplots()\nax1.plot(X[:,1], Y, \"x\")\nplt.style.use('seaborn-notebook')\nax1.grid()\nfig1.savefig(\"fig1.png\", dpi=300)\n\nFigure 1: Scatterplot of data drawn using\nunif(-10,10) as noise.Now we need to implement the perceptron. Given a loss function, it\ngoes as follows:\ninit \\(\\textbf{w}\\sim\nrunif(0,1)\\)\ncalculate cost (MSE)\nupdate weights according to gradient\nrepeat 2-3 until some stopping rule (could be number of iterations,\ncould be stability of weights, up to us).\nThere are some other things that we should talk about,\ntrain/validate/test sets, etc, but we will skip for this post. For now,\nlet’s just do it:\n\n\n## ok, do gradient descent\ndef gradient_descent(x, y, w_init, learning_rate):\n    N = x.shape[0]\n    w_grad = w_init\n    ## need a stopping rule, could just be iterations, could also be a min move\n    ## using matrix algebra to simplify this a bit\n    maxIteration = 100000\n    for i in range(maxIteration):\n        error = y - x * w_grad #observed - predicted\n        gradient = -2/N * (x.T * error)\n        w_grad = w_grad - learning_rate * gradient\n    return w_grad\n\nw_start = np.matrix([[0],[0]])\nlearning_rate = 0.001\nw = gradient_descent(X,Y,w_start,learning_rate)\n\n# exact solution using slr inv(x'x)*x'y\nw_exact = np.linalg.inv(X.T*X)*X.T*Y\n\n# take a peak at our how we did\nfig2, ax2 = plt.subplots()\nplt.style.use('seaborn-notebook')\nax2.plot(X[:,1], X * w, color=\"red\")\nax2.scatter(np.ravel(X[:,1]),np.ravel(Y), marker=\"2\", color=\"blue\")\nax2.text(25,50,(\"b = \" + str(round(w[0,0],2)) + \"; m = \" + str(round(w[1,0],2))))\nax2.text(25,40,(\"b.exact = \" + str(round(w_exact[0,0],2)) + \"; m.exact = \" + str(round(w_exact[1,0],2))))\nax2.set_ylabel(\"Y\")\n\nax2.grid()\nfig2.savefig(\"fig2.png\", dpi=300)\n\nFigure 2: perceptron learning of weights\n(1,3) after 10k iterations.Example 2: binary\nclassification\nThis starts the same way: get some data. Let’s simulate it again, in\na future post, we will go through a more expansive and real dataset. For\nnow, let’s imagine a scenario where we are insterested in\nMulticlass perceptrons\nMultilayer Perceptrons\n\n\n\n",
    "preview": "deeplearning/images/perceptron.drawio.png",
    "last_modified": "2022-06-20T09:14:33-04:00",
    "input_file": {},
    "preview_width": 327,
    "preview_height": 251
  }
]
