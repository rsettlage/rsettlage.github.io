[
  {
    "path": "posts/2022-05-28-mcmc-inspiration/",
    "title": "MCMC inspiration",
    "description": "Details of why MCMC for me.",
    "author": [
      {
        "name": "Robert Settlage",
        "url": {}
      }
    ],
    "date": "2022-05-31",
    "categories": [],
    "contents": "\n\nContents\nBayesian learning\nLife, Bayes, statistics\nand data\nReject Method\nExample: Prior \\(\\rightarrow\\) Posterior\n\nIllustrative Example\nfrom article\nPaper example\nusing Weighted Bootstrap\nPaper\nexample using Accept-Reject following burn-in\n\n\nI have always liked simulating stuff. Trying to code up a game of\nlife, looking at fractal evolutions, etc. The first time I saw a random\nwalk, I was super intrigued. In the Virginia Tech Statistics masters\nprogram, I had the fortune of taking Scotland Lemon’s MCMC course. Not\nonly is he a fantastic teacher, the material was just what I had been\nwanting: some serious compute topics.\nHere, I am going to start with what I see as the motivation for MCMC\nas detailed in:\n\nSmith and Gelfand, Bayesian statistics without tears: A\nsampling-resampling perspective, 1992 DOI:10.1080/00031305.1992.10475856.\n\nBayesian learning\nBayesian learning is a highly daunting subject to the uninitiated. To\nboil it down, it is stated as updating beliefs (developing a new\nunderstanding) through data. More statistically, updating prior\nknowledge through the likelihood function given observed data. The whole\ntenant is given in three equations:\n\\[\n\\begin{equation}\n\\tag{1}\np(\\theta|\\textbf{X}) = \\frac{\\ell(\\theta, \\textbf{X}) \\ast\np(\\theta)}{\\int{\\ell(\\theta, \\textbf{X}) \\ast p(\\theta) d\\theta}}\n\\end{equation}\n\\]\nFurther, if \\(\\theta\\) is composed\nof multiple random variables, eg \\(\\theta=\\{\\phi,\\psi\\}\\) where we are only\ninterested in, say, \\(\\phi\\), we can\nrefocus the above by integrating out the effect of the uninteresting\nvariable \\(\\psi\\):\n\\[\n\\begin{equation}\n\\tag{2}\np(\\phi|\\textbf{X}) = \\int \\ell(\\phi,\\psi\\, \\textbf{X}) d\\psi\n\\end{equation}\n\\]\nSimilarly, if we are interested in some sort of summary stat, for\ninstance, we want location or spread (mean/variance), we can compute\nthese in the normal way as:\n\\[\n\\begin{equation}\n\\tag{3}\nE[m(\\theta)|\\textbf{X}] = \\int m(\\theta)p(\\theta)|\\textbf{X}) d\\theta\n\\end{equation}\n\\]\nwhere m(\\(\\ast\\)) is chosen for the\ndesired summary stat. These three equations, taken directly from Smith\nand Goldfand, are the foundation of Bayesian learning and at the same\ntime are the fundamentals of Monte Carlo methods.\nLife, Bayes, statistics and\ndata\nLife is about having one thing and needing another, statistics and\ndata are no different. Suppose we can get samples from g(\\(\\theta\\)) but need them from h(\\(\\theta\\)), we might end at the following\nquestions stated by Smith and Gelfand:\nCan we utilize samples from g(\\(\\theta\\)) to get a sample from h(\\(\\theta\\))?\nGiven f(\\(\\theta\\)) which is\nnormalizable to form \\(h(\\theta) =\n\\frac{f(\\theta)}{\\int{f(\\theta) d\\theta}}\\). Can we compute a\nsample from h(\\(\\theta\\)), given only a\nsample from g(\\(\\theta\\))?\nSo, the answers turns out to be yes.\nSmith and Gelfand go on the describe the \\(Reject\\ Method\\) and give an example. I\nwill repeat both and provide some code.\nReject Method\nWe want h(\\(\\theta\\)), but have\ng(\\(\\theta\\)). Additionally, we know\n\\(h(\\theta) = \\frac{f(\\theta)}{\\int{f(\\theta)\nd\\theta}}\\) and that there exists some constant \\(M>0\\) where \\(\\frac{f(\\theta)}{g(\\theta)} \\le M\\).\nProcedure:\ngenerate \\(\\theta \\sim\ng(\\theta)\\)\ngenerate \\(u \\sim\n\\text{unif}(0,1)\\)\nif \\(u \\le\n\\frac{f(\\theta)}{Mg(\\theta)}\\) accept (accept with probability\nu), else reject\nrepeat 1-3\nAny accepted \\(\\theta\\) is a random\nvariate from \\(h(\\theta) =\n\\frac{f(\\theta)}{\\int f(\\theta) d\\theta}\\). The proof is\nrelatively simple and given in about 3 lines in the Smith and Gelfand\npaper where I will point you if you need to see it.\nWe do have one item to clean up, if we don’t know M:\n\\[\n\\begin{eqnarray}\n\\tag{4}\nM &=& \\int f(\\theta) d\\theta \\approx \\frac{1}{n} \\sum_i \\omega_i\n\\text{ , where } \\\\\n\\tag{5}\n\\omega_i &=& \\frac{f(\\theta_i)}{g(\\theta_i)}\n\\end{eqnarray}\n\\] It took me seeing the above in (4) to finally get why Scotland\ntook so much time on Monte Carlo integration. It’s just hidden\neverywhere.\nOr alternatively, we could use \\(Weighted\\\nBootstrapping\\) where we draw \\(\\theta^{\\ast}\\) from a realization of \\(\\theta = \\{\\theta_1 \\dots \\theta_n\\}\\).\nFrom this we can calculate: \\[\n\\begin{equation}\nq_i = \\frac{\\omega_i}{\\sum_j \\omega_j} \\text{ ; } \\omega_{[i,j]} \\text{\ngiven in (5)}\n\\end{equation}\n\\]\nNow \\(q_i\\) is our sampling\nprobability for drawing from the \\(\\theta_i\\)’s.\nExample: Prior \\(\\rightarrow\\) Posterior\nWe have prior knowledge in \\(p(\\theta)\\) and want to update our\nknowledge base given new information via the posterior \\(p(\\theta | \\textbf{X})\\).\nIf we let: \\[\n\\begin{eqnarray}\n\\tag{6}\nf_x(\\theta) &=& \\ell(\\theta|\\textbf{X}) p(\\theta)  \\\\\n\\tag{7}\ng(\\theta) &=& p(\\theta) \\text{, further, if we know }\n\\hat{\\theta}_{ML}  \\\\\n\\tag{8}\nM &=& \\ell(\\hat{\\theta|}\\textbf{X})\n\\end{eqnarray}\n\\]\nSo, returning to our procedure, we need to accept with probability\nu\n\\[\n\\begin{eqnarray}\n\\tag{9}\nu &\\le& \\frac{f(\\theta)}{Mg(\\theta)} \\\\\n  &\\le& \\frac{\\ell(\\theta|\\textbf{X})\np(\\theta)}{\\ell(\\hat{\\theta|}\\textbf{X})p(\\theta)} \\\\\n  &\\le&\n\\frac{\\ell(\\theta|\\textbf{X})}{\\ell(\\hat{\\theta|}\\textbf{X})}\n\\end{eqnarray}\n\\]\nWell, that is cool. Essentially the likelihood is acting as the\nmodulator for the resampling probability. Highly likely \\(\\theta\\)’s will have higher probability of\nbeing sampled as indicated by the observed data.\nIllustrative Example from\narticle\nSmith and Gelfand reworked an example originally given by McCullagh\nand Nelder, Generalized Linear Models, 1989. Essentially, consider two\nconditionally independent (given their parameters) random variables\nobserved 3 times through their sum:\n\\[\n\\begin{eqnarray}\n\\tag{10}\n\\textbf{X}_{i1} &\\sim& Binomial(n_{i1}, \\theta_1) \\\\\n\\tag{11}\n\\textbf{X}_{i2} &\\sim& Binomial(n_{i2}, \\theta_2) \\\\\n\\tag{12}\n\\textbf{Y}_i &=& \\textbf{X}_{i1} + \\textbf{X}_{i2}; i \\in\n\\{1,2,3\\}\n\\end{eqnarray}\n\\]\nWe can create the likelihood as (fixing mistake in paper):\n\\[\n\\begin{equation}\n\\tag{13}\n\\ell(\\theta_1,\\theta_2 | \\textbf{Y}, i \\in \\{1,2,3\\}) = \\prod_{i=1}^{3}\n\\left[\\sum_{j_i} {{n_{i1}}\\choose{j_i}} {{n_{i2}}\\choose{y_i-j_i}} \\ast\n\\theta_1^{j_i}(1-\\theta_1)^{n_{i1}-y_i}\\theta_2^{y_i-j_i}(1-\\theta_2)^{n_{i2}-y_i+j_i}\\right]\n\\end{equation}\n\\]\nAnd are given the following as data:\n\n\n\n\n\ni\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\\(n_{i1}\\)\n\n\n5\n\n\n6\n\n\n4\n\n\n\\(n_{i2}\\)\n\n\n5\n\n\n4\n\n\n6\n\n\n\\(y_i\\)\n\n\n7\n\n\n5\n\n\n6\n\n\nOk, so our data shows observed sums of \\(Y_i =X_1 + X_2\\) going from 5 to 7 given\nthe unknown \\(\\theta_j, j \\in\n\\{1,2\\}\\).\nPaper example using\nWeighted Bootstrap\nFollowing the paper, we will consider priors on both \\(\\theta_1\\) and \\(\\theta_2\\) as uniform(0,1) where the\nauthors generated about 1000 \\(\\theta_1,\n\\theta_2\\) pairs. Following suit:\n\n\nset.seed(15239) # just a random number as seed\nobservations <- 1000\nt1 <- runif(n=observations, min=0, max=1)\nt2 <- runif(n=observations, min=0, max=1)\ntheta_draws <- data.frame(theta1=t1, theta2=t2)\n\n\n\n\n\n\nWe now sample from these priors using the weighted bootstrap\nproceedure as outlined above. To get at the weights, we need to start by\ncalculating \\(q_i\\). Remembering \\(\\omega_i =\n\\frac{f(\\theta_i)}{g(\\theta_i)}\\), \\(g(\\theta_i) = p(\\theta_i)\\) and \\(f(\\theta_i) =\n\\ell(\\theta_i|\\textbf(X_i))p(\\theta_i)\\)\n\\[\n\\begin{eqnarray}\nq_i &=& \\frac{\\omega_i}{\\sum_{j=1}^n \\omega_j} \\\\\n  &=& \\frac{\\frac{f(\\theta_i)}{g(\\theta_i)}}{\\sum_{j=1}^n\n\\frac{f(\\theta_j)}{g(\\theta_j)}} \\\\\n  &=& \\frac{\\ell(\\theta_i|\\textbf(X_i))}{\\sum_{j=1}^n\n\\ell(\\theta_j|\\textbf(X_j))}\n\\end{eqnarray}\n\\] I have been a little lax in the i, j in this. Here i refers to\nthe ith draw from the priors and j runs across all draws. Note that as\nwe inspect (13), we encounter \\(j_i\\).\nThis represents the possible values of \\(\\textbf{X}_i\\) given the parameters, \\(n_{i1}\\) and \\(n_{i2}\\), and observed \\(y_i\\), so \\(max(0, y_i-n_{i2}) \\le j_i \\le min(n_{i1},\ny_i)\\). Let’s code this up and get our \\(q_i\\)’s.\n\n\nji_min_max <- data.frame(min=c(2,1,0),max=c(5,5,4))\nomega <- rep(1,observations)\nfor(k in 1:observations){\n  for(i in 1:3){\n    ji <- ji_min_max[i,1]\n    temp_omega <- 0\n    while(ji<ji_min_max[i,2]){\n      temp_omega <- temp_omega +\n        choose(test_data[1,i],ji)*choose(test_data[2,i],test_data[3,i]-ji)*\n        (theta_draws$theta1[k]^ji)*((1-theta_draws$theta1[k])^(test_data[1,i]-ji))*\n        (theta_draws$theta2[k]^(test_data[3,i]-ji))*\n        ((1-theta_draws$theta2[k])^(test_data[2,i]-test_data[3,i]+ji))\n      ji <- ji+1\n    }\n    omega[k] <- omega[k] * temp_omega\n  }\n}\nq_i <- omega/sum(omega)\n\n\n\nNow do the draws according to the \\(q_i\\)’s and calc the posterior.\n\n\nthetas_index <- sample(1:observations, size=1000, replace=TRUE, prob=q_i) \nh <- omega[thetas_index]\n\n\n\n\n\n\nNote, no point in the above posterior is NOT in the previous plot of\nprior draws. The paper appears to have used a different set of points\nfor the plot of the posterior.\nPaper\nexample using Accept-Reject following burn-in\nBefore I close, I would like to do this another way, let’s estimate M\non the fly and use “burn-in” to iteratively converge on M and do a real\naccept/reject. I will again pull from uniforms as my prior (future post\nto play with priors?), but will keep track of the proposals vs\naccept/reject to see if an interesting plot emerges.\n\n\nji_min_max <- data.frame(min=c(2,1,0),max=c(5,5,4))\n#quick funtion to calc f(theta)=likelihood, basically took from above\nlhood <- function(t1=0.5,t2=0.5,tdata=test_data,ji_minimax=ji_min_max){\n  for(i in 1:3){\n    ji <- ji_minimax[i,1]\n    temp_likelihood <- 0\n    current_likelihood <- 1\n    while(ji<ji_minimax[i,2]){\n      temp_likelihood <- temp_likelihood +\n        choose(tdata[1,i],ji)*choose(tdata[2,i],tdata[3,i]-ji)*\n        (t1^ji)*((1-t1)^(tdata[1,i]-ji))*\n        (t2^(tdata[3,i]-ji))*((1-t2)^(tdata[2,i]-tdata[3,i]+ji))\n      ji <- ji+1\n    }\n    current_likelihood <- current_likelihood * temp_likelihood\n  }\n  return(current_likelihood)\n}\n\nstored_thetas <- rbind(data.frame(theta1=0,theta2=0,likelihood=0,u=0,accept=1,M=0),\n                       data.frame(theta1=0,theta2=0,likelihood=0,u=0,accept=1,M=0))\nk <- 2\nprevious_M <- 0\n## actual accept/reject\nwhile(sum(stored_thetas$accept)<10000){\n  k <- k+1\n  # 1. make proposal(s)\n  # 2. generate u from uniform(0,1)\n  stored_thetas <- rbind(stored_thetas,\n                         data.frame(theta1=runif(1,0,1),theta2=runif(1,0,1),\n                              u=runif(1,0,1),likelihood=0,accept=0,M=0))\n  # 3. if u <= f/(Mg) then accept, else reject, repeat\n  \n  stored_thetas$likelihood[k] <- lhood(stored_thetas$theta1[k],\n                                            stored_thetas$theta2[k])\n  # calc running M real quick\n  M <- mean(stored_thetas$likelihood[stored_thetas$accept>0])\n  # accpet or reject?\n  stored_thetas$accept[k] <-\n    ifelse(stored_thetas$u[k]<stored_thetas$likelihood[k]/M,1, 0)\n  # update M if needed, this is for status indicator\n  stored_thetas$M[k] <-\n    ifelse(stored_thetas$accept[k]==1,M,stored_thetas$M[k-1])\n  if(stored_thetas$accept[k]==1){\n    M_change <- stored_thetas$M[k]-stored_thetas$M[k-1]\n  }\n  \n  # little status indicator\n  if((k %% 1000)==0){\n    cat(\"current k: \", k, \" current accepted: \", sum(stored_thetas$accept),\n      \" current/change in M:\", M,\" : \", M_change, \"\\n\",sep=\"\")\n  }\n}\n\n\ncurrent k: 1000 current accepted: 452 current/change in M:0.1967587 : -0.000284144\ncurrent k: 2000 current accepted: 932 current/change in M:0.2024283 : -9.629906e-05\ncurrent k: 3000 current accepted: 1417 current/change in M:0.2009935 : -4.114977e-05\ncurrent k: 4000 current accepted: 1865 current/change in M:0.2008423 : -9.366024e-05\ncurrent k: 5000 current accepted: 2333 current/change in M:0.1992392 : -4.590816e-05\ncurrent k: 6000 current accepted: 2804 current/change in M:0.1992795 : 4.192012e-06\ncurrent k: 7000 current accepted: 3296 current/change in M:0.1997426 : -1.830395e-05\ncurrent k: 8000 current accepted: 3768 current/change in M:0.2011892 : 1.26757e-05\ncurrent k: 9000 current accepted: 4201 current/change in M:0.2017363 : -1.827057e-05\ncurrent k: 10000 current accepted: 4690 current/change in M:0.2014897 : 4.914835e-05\ncurrent k: 11000 current accepted: 5187 current/change in M:0.2015779 : 1.636161e-05\ncurrent k: 12000 current accepted: 5657 current/change in M:0.2017894 : -8.658366e-06\ncurrent k: 13000 current accepted: 6116 current/change in M:0.2009656 : -2.302136e-05\ncurrent k: 14000 current accepted: 6585 current/change in M:0.2010067 : 6.980897e-06\ncurrent k: 15000 current accepted: 7054 current/change in M:0.2017694 : 4.251824e-06\ncurrent k: 16000 current accepted: 7536 current/change in M:0.2019006 : 6.399018e-06\ncurrent k: 17000 current accepted: 8011 current/change in M:0.202628 : -9.512693e-06\ncurrent k: 18000 current accepted: 8475 current/change in M:0.2031243 : 1.733376e-06\ncurrent k: 19000 current accepted: 8943 current/change in M:0.2029498 : 2.093441e-05\ncurrent k: 20000 current accepted: 9452 current/change in M:0.2023991 : 2.138806e-06\ncurrent k: 21000 current accepted: 9901 current/change in M:0.2022406 : -1.338133e-05\n\nstored_thetas <- stored_thetas[-c(1,2),]\ncat(\"final M is: \",M, \"\\n\",sep=\"\")\n\n\nfinal M is: 0.2021795\n\n\n\n\nOK, so, we see a slightly different final location for our \\(\\theta\\)’s, but that is expected as we are\nsampling more finely and letting the accept-reject criterion determine\nwhich prior values are more likely. An interesting feature to me is the\naccept region appears more able to expand into the reject region than\nthe converse. Perhaps I am just looking at it too critically.\nThings to think about for a future post:\ndifferent priors\niterate on \\(\\theta\\)’s, ie fix\none, sample other, alternate\nothers … ??\n\n\n\n",
    "preview": "posts/2022-05-28-mcmc-inspiration/mcmc-inspiration_files/figure-html5/plot_priors-1.png",
    "last_modified": "2022-05-31T05:49:52-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
